{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d51f4020-8cb4-4561-b6d2-98589737dda8",
   "metadata": {},
   "source": [
    "# LangGraphë¥¼ ì‚¬ìš©í•œ ê³ ê° ì§€ì› ì±—ë´‡ì„ êµ¬ì¶•\n",
    "\n",
    "- ì›¹ ê²€ìƒ‰ì„ í†µí•´ ì¼ë°˜ì ì¸ ì§ˆë¬¸ì— ë‹µë³€ \n",
    "- ëŒ€í™” ìƒíƒœë¥¼ ìœ ì§€í•˜ì—¬ ì—°ì†ì ì¸ ëŒ€í™”  \n",
    "- ë³µì¡í•œ ì§ˆë¬¸ì„ ì‚¬ëŒì´ ê²€í† í•˜ë„ë¡ ë¼ìš°íŒ…  \n",
    "- ì‚¬ìš©ì ì§€ì • ìƒíƒœ(Custom State)ë¥¼ í™œìš©í•˜ì—¬ ì±—ë´‡ì˜ ë™ì‘ ì œì–´  \n",
    "- ëŒ€í™” íë¦„ì„ ë˜ëŒë¦¬ê³ (Rewind), ë‹¤ë¥¸ ëŒ€í™” ê²½ë¡œ íƒìƒ‰ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a213aa99-6fe2-465e-a21b-b743cabfb74e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb0aec0a-9a1e-45a3-bf66-d89895d172f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangSmith ì¶”ì  ì„¤ì • í™œì„±í™”\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fec86f20-d4b0-4cfa-99a9-0c5a281f40f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4.1-nano\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df89407-dce9-4ce5-bca0-4e3b04cd17cd",
   "metadata": {},
   "source": [
    "ë¨¼ì € ëª¨ë¸ì„ ì§ì ‘ ì‚¬ìš©í•´ ë´…ë‹ˆë‹¤. `ChatModel`ì€ LangChainì˜ **\"Runnable\"** ì¸ìŠ¤í„´ìŠ¤ì´ë©°, ì´ëŠ” í‘œì¤€í™”ëœ ì¸í„°í˜ì´ìŠ¤ë¥¼ í†µí•´ ìƒí˜¸ì‘ìš©í•  ìˆ˜ ìˆìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.  \n",
    "\n",
    "ëª¨ë¸ì„ ê°„ë‹¨í•˜ê²Œ í˜¸ì¶œí•˜ë ¤ë©´ `.invoke` ë©”ì„œë“œì— **ë©”ì‹œì§€ ëª©ë¡**ì„ ì „ë‹¬í•˜ë©´ ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6448ed23-0ce7-4431-a4a2-793a0916d3de",
   "metadata": {},
   "source": [
    "## ë„êµ¬ë¥¼ í™œìš©í•œ ì±—ë´‡ ê°•í™”**   \n",
    "ì´ì œ ì±—ë´‡ì´ **ì›¹ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì•„ ë” ë‚˜ì€ ë‹µë³€ì„ ì œê³µí•  ìˆ˜ ìˆë„ë¡ ê°œì„ **í•©ë‹ˆë‹¤. \n",
    "\n",
    "---\n",
    "ë¨¼ì € **Tavily ê²€ìƒ‰ ì—”ì§„**ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ê³  **`TAVILY_API_KEY`** ë¥¼ ì„¤ì • í•©ë‹ˆë‹¤.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d7a4b30-dbfe-4a97-930e-dd021949c6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture --no-stderr\n",
    "#%pip install -U langchain-tavily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7653298e-26bc-4552-af74-ad5fd2e9d8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'LangGraphì—ì„œ nodeê°€ ë­ì•¼?', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'LangGraphì˜ í•µì‹¬ êµ¬ì¡°: Node & Edge : ë„¤ì´ë²„ ë¸”ë¡œê·¸', 'url': 'https://blog.naver.com/oaziz/223839790474', 'content': 'LangGraphì˜ í•µì‹¬ êµ¬ì¡°: Node & Edge 1. ğŸ§± Node (ë…¸ë“œ): ì‘ì—… ë‹¨ìœ„ (ì‘ì—…ì í˜¹ì€ ì²˜ë¦¬ ë‹¨ê³„) ğŸ¯ ì •ì˜ í•˜ë‚˜ì˜ ë…¸ë“œëŠ” í•˜ë‚˜ì˜ ê¸°ëŠ¥ ë˜ëŠ” í•˜ë‚˜ì˜ ì²˜ë¦¬ ë‹¨ê³„ë¥¼ ë‹´ë‹¹í•©ë‹ˆë‹¤. ì˜ˆ: LLM í˜¸ì¶œ, retriever ì‹¤í–‰, ìš”ì•½, ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ ë“± ğŸ›  Nodeì—ëŠ” ë³´í†µ ë‹¤ìŒê³¼ ê°™ì€ í•¨ìˆ˜ê°€ ë“¤ì–´ê°‘ë‹ˆë‹¤:', 'score': 0.8719229, 'raw_content': None}, {'title': 'Nodes and Edges | langchain-ai/langgraph-101 | DeepWiki', 'url': 'https://deepwiki.com/langchain-ai/langgraph-101/2.2-nodes-and-edges', 'content': 'Nodes and Edges | langchain-ai/langgraph-101 | DeepWiki Nodes and Edges Nodes and Edges What are Nodes and Edges? In LangGraph, a graph is composed of nodes connected by edges to form a directed workflow. Nodes are the workhorses of LangGraph - they are Python functions that receive the current graph state as input, perform operations, and return updates to that state. Edges define the flow of execution between nodes in a LangGraph. graph_builder.add_edge(\"retrieve_documents\", \"generate_response\") Conditional edges use a function to determine the next node based on the current state. Building a Graph with Nodes and Edges graph_builder.add_node(\"retrieve_documents\", retrieve_documents) graph_builder.add_edge(\"retrieve_documents\", \"generate_response\") When designing nodes and edges in LangGraph: Nodes and Edges What are Nodes and Edges? Building a Graph with Nodes and Edges', 'score': 0.85157084, 'raw_content': None}], 'response_time': 1.18}\n"
     ]
    }
   ],
   "source": [
    "# Tavily ê²€ìƒ‰ íˆ´ì„ ì„í¬íŠ¸\n",
    "# TavilyëŠ” ì›¹ ê²€ìƒ‰ì„ í†µí•´ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë„êµ¬ë¡œ, LangChainì—ì„œ ë„êµ¬(tool)ë¡œ í™œìš© ê°€ëŠ¥\n",
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "# TavilySearch íˆ´ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„± (ìµœëŒ€ ê²°ê³¼ 2ê°œë¡œ ì œí•œ)\n",
    "tool = TavilySearch(max_results=2)\n",
    "\n",
    "# ì‚¬ìš©í•  íˆ´ë“¤ì„ ë¦¬ìŠ¤íŠ¸ë¡œ êµ¬ì„± (ì—¬ëŸ¬ ê°œì˜ ë„êµ¬ê°€ í•„ìš”í•œ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì‘ì„±)\n",
    "tools = [tool]\n",
    "\n",
    "# Tavily ê²€ìƒ‰ ë„êµ¬ë¥¼ ì§ì ‘ í˜¸ì¶œí•˜ì—¬ \"LangGraphì—ì„œ nodeê°€ ë­ì•¼?\"ë¼ëŠ” ì§ˆë¬¸ì— ëŒ€í•œ ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜´\n",
    "result = tool.invoke(\"LangGraphì—ì„œ nodeê°€ ë­ì•¼?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53ea529c-b7e9-40fa-b4c5-148435c2bb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U \"langchain[openai]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20a6e98-1fee-4815-8a0e-b61870abe3d0",
   "metadata": {},
   "source": [
    "### ì—ì´ì „íŠ¸ ìƒì„±í•˜ê¸°\n",
    "ì´ì œ ë„êµ¬ë“¤ê³¼ LLM(ì–¸ì–´ ëª¨ë¸)ì„ ì •ì˜í–ˆìœ¼ë‹ˆ, ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” **LangGraph**ë¥¼ ì‚¬ìš©í•˜ì—¬ ì—ì´ì „íŠ¸ë¥¼ êµ¬ì„±í•  ê²ƒì…ë‹ˆë‹¤. í˜„ì¬ëŠ” **ìƒìœ„ ìˆ˜ì¤€ì˜ ì¸í„°í˜ì´ìŠ¤**ë¥¼ ì‚¬ìš©í•˜ì—¬ ì—ì´ì „íŠ¸ë¥¼ ë§Œë“¤ê³  ìˆì§€ë§Œ, LangGraphì˜ ì¥ì ì€ ì´ ìƒìœ„ ìˆ˜ì¤€ ì¸í„°í˜ì´ìŠ¤ê°€ **í•˜ìœ„ ìˆ˜ì¤€ì˜ ê³ ë„ë¡œ ì œì–´ ê°€ëŠ¥í•œ API**ë¡œ ì§€ì›ëœë‹¤ëŠ” ì ì…ë‹ˆë‹¤. ë”°ë¼ì„œ ë‚˜ì¤‘ì— ì—ì´ì „íŠ¸ ë¡œì§ì„ ììœ ë¡­ê²Œ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì—ì´ì „íŠ¸ëŠ” ì„¸ ê°€ì§€ êµ¬ì„± ìš”ì†Œë¡œ ì´ë£¨ì–´ì ¸ ìˆìŠµë‹ˆë‹¤:\n",
    "**ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)**, ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” **ë„êµ¬ë“¤ì˜ ì§‘í•©**, ê·¸ë¦¬ê³  **ì§€ì‹œì‚¬í•­ì„ ë‹´ì€ í”„ë¡¬í”„íŠ¸**ì…ë‹ˆë‹¤.\n",
    "\n",
    "LLMì€ ë£¨í”„ ë°©ì‹ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤. ê° ë°˜ë³µ(iteration)ë§ˆë‹¤ ë‹¤ìŒê³¼ ê°™ì€ ê³¼ì •ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:\n",
    "\n",
    "1. ì‚¬ìš©í•  ë„êµ¬ë¥¼ ì„ íƒí•˜ê³ ,\n",
    "2. ê·¸ ë„êµ¬ì— ì…ë ¥ì„ ì œê³µí•˜ë©°,\n",
    "3. ê²°ê³¼(ê´€ì°°ê°’, observation)ë¥¼ ë°›ì•„ì˜¤ê³ ,\n",
    "4. ê·¸ ê´€ì°°ê°’ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ í–‰ë™ì„ ê²°ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ ë£¨í”„ëŠ” **ì¤‘ì§€ ì¡°ê±´**ì´ ì¶©ì¡±ë  ë•Œê¹Œì§€ ê³„ì†ë˜ë©°, ì¼ë°˜ì ìœ¼ë¡œëŠ” **ì‚¬ìš©ìì—ê²Œ ì‘ë‹µí•˜ê¸°ì— ì¶©ë¶„í•œ ì •ë³´ë¥¼ ìˆ˜ì§‘í–ˆì„ ë•Œ** ì¢…ë£Œë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18075f1c-f8f3-4b1d-838f-201f848109e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant functionality\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# Create the agent\n",
    "memory = MemorySaver()\n",
    "search = TavilySearch(max_results=2)\n",
    "tools = [search]\n",
    "agent_executor = create_react_agent(model, tools, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f22d647-3fff-463c-944a-bda95b837938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "ì•ˆë…•, ë‚œ ê¸¸ë™ì´ì•¼. ì§€ê¸ˆ ì„œìš¸ì˜ ë‚ ì”¨ê°€ ì–´ë•Œ?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search (call_kNO3JvzpOMPVGnJVQDtucL4R)\n",
      " Call ID: call_kNO3JvzpOMPVGnJVQDtucL4R\n",
      "  Args:\n",
      "    query: ì„œìš¸ ì˜¤ëŠ˜ ë‚ ì”¨\n",
      "    search_depth: basic\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"ì„œìš¸ ì˜¤ëŠ˜ ë‚ ì”¨\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://weather.com/ko-KR/weather/today/l/18e81cdf57491c51a6fba3c57732b7b61bdf511fc2b613570316978b9f20687a\", \"title\": \"ì„œìš¸íŠ¹ë³„ì‹œ ì¼ê¸°ì˜ˆë³´ ë° ë‚ ì”¨ - The Weather Channel\", \"content\": \"ì˜¤ëŠ˜ ì„œìš¸íŠ¹ë³„ì‹œì˜ ë‚ ì”¨ ì˜ˆë³´ ; ìµœê³ /ìµœì €. --/20Â° ; ë°”ëŒ. 6 km/h ; ìŠµë„. 61% ; ì´ìŠ¬ì . 17Â° ; ê¸°ì••. 1012.2 mb.\", \"score\": 0.8235701, \"raw_content\": null}, {\"url\": \"https://www.accuweather.com/ko/kr/seoul/226081/hourly-weather-forecast/226081\", \"title\": \"ì„œìš¸íŠ¹ë³„ì‹œ, ì„œìš¸ì‹œ, ëŒ€í•œë¯¼êµ­ ì‹œê°„ë³„ ë‚ ì”¨ - AccuWeather\", \"content\": \"ì„œìš¸íŠ¹ë³„ì‹œ, ì„œìš¸ì‹œ, ëŒ€í•œë¯¼êµ­ ì‹œê°„ë³„ ë‚ ì”¨ | AccuWeather ì„œìš¸íŠ¹ë³„ì‹œ, ì„œìš¸ì‹œ ========== 65Â°F í˜„ì¬ ìœ„ì¹˜ ì‚¬ìš© ì„œìš¸íŠ¹ë³„ì‹œ ì„œìš¸ì‹œ 65Â° ì„œìš¸íŠ¹ë³„ì‹œ, ì„œìš¸ì‹œ ë‚ ì”¨ ì˜¤ëŠ˜WinterCastì§€ì—­ {stormName} ì¶”ì ê¸°ì‹œê°„ë³„ì¼ë³„ë ˆì´ë”MinuteCastì›”ëŒ€ê¸°ì§ˆê±´ê°• ë° í™œë™ ì „ ì„¸ê³„ ### í—ˆë¦¬ì¼€ì¸### ì•…ì²œí›„ ê¸°ìƒ### ë ˆì´ë” ë° ì§€ë„### ë™ì˜ìƒ ì˜¤ëŠ˜ì‹œê°„ë³„ ---ì¼ë³„ë ˆì´ë”MinuteCastì›”ëŒ€ê¸°ì§ˆê±´ê°• ë° í™œë™ 64Â° RealFeelÂ® 65Â°  ë§‘ìŒ ë°”ëŒ ì„œë‚¨ì„œ 4mi/h ëŒí’ 9mi/h ê°€ì‹œê±°ë¦¬ 10mi 62Â° RealFeelÂ® 62Â°  ëŒ€ì²´ë¡œ ë§‘ìŒ ë°”ëŒ ë‚¨ì„œ 4mi/h ëŒí’ 7mi/h ê°€ì‹œê±°ë¦¬ 10mi 59Â° RealFeelÂ® 60Â°  ë°”ëŒ ë‚¨ì„œ 2mi/h ëŒí’ 7mi/h ê°€ì‹œê±°ë¦¬ 10mi ì „ ì„¸ê³„ ### í—ˆë¦¬ì¼€ì¸### ì•…ì²œí›„ ê¸°ìƒ### ë ˆì´ë” ë° ì§€ë„### ë™ì˜ìƒ ì „ ì„¸ê³„ì•„ì‹œì•„ëŒ€í•œë¯¼êµ­ì„œìš¸ì‹œì„œìš¸íŠ¹ë³„ì‹œ ë™ì‘êµ¬, ì„œìš¸ì‹œ ë§ˆí¬êµ¬, ì„œìš¸ì‹œ ì„œëŒ€ë¬¸êµ¬, ì„œìš¸ì‹œ ì´ìš© ì•½ê´€ | ê°œì¸ì •ë³´ ë³´í˜¸ì •ì±… | ì¿ í‚¤ ì‚¬ìš© ì •ì±…|ê°œì¸ì •ë³´ ë³´í˜¸ ì •ë³´ ë‚´ ê°œì¸ ì •ë³´ë¥¼ íŒë§¤í•˜ê±°ë‚˜ ê³µìœ í•˜ì§€ ë§ˆì‹­ì‹œì˜¤. Get AccuWeather alerts as they happen with our browser notifications. Enable Notifications Notifications Enabled\", \"score\": 0.7923522, \"raw_content\": null}], \"response_time\": 1.36}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ì˜¤ëŠ˜ ì„œìš¸ì˜ ë‚ ì”¨ëŠ” ëŒ€ì²´ë¡œ ë§‘ê±°ë‚˜ êµ¬ë¦„ ì¡°ê¸ˆ ìˆìœ¼ë©°, ìµœê³  ê¸°ì˜¨ì€ ì•½ 20ë„ ì •ë„ì…ë‹ˆë‹¤. ìŠµë„ëŠ” 61%ì´ê³ , ë°”ëŒì€ 6 km/hë¡œ ë¶ˆê³  ìˆìŠµë‹ˆë‹¤. ë„ì›€ì´ ë” í•„ìš”í•˜ë©´ ë§ì”€í•´ ì£¼ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "# Use the agent\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "\n",
    "input_message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"ì•ˆë…•, ë‚œ ê¸¸ë™ì´ì•¼. ì§€ê¸ˆ ì„œìš¸ì˜ ë‚ ì”¨ê°€ ì–´ë•Œ?\",\n",
    "}\n",
    "for step in agent_executor.stream(\n",
    "    {\"messages\": [input_message]}, config, stream_mode=\"values\"\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c7a1b5-6039-4915-9b70-61b4d825737f",
   "metadata": {},
   "source": [
    "## ì±—ë´‡ì— ë©”ëª¨ë¦¬ ê¸°ëŠ¥ ì¶”ê°€Â¶**  \n",
    "\n",
    "í˜„ì¬ ì±—ë´‡ì€ **ì‚¬ìš©ì ì§ˆë¬¸ì— ë„êµ¬ë¥¼ í™œìš©í•´ ë‹µë³€í•  ìˆ˜ ìˆì§€ë§Œ, ì´ì „ ëŒ€í™”ì˜ ë§¥ë½ì„ ê¸°ì–µí•˜ì§€ ëª»í•©ë‹ˆë‹¤.**  \n",
    "ì´ ë•Œë¬¸ì— **ì¼ê´€ëœ ë©€í‹°í„´(Multi-turn) ëŒ€í™”ë¥¼ ì§„í–‰í•˜ëŠ” ë° í•œê³„ê°€ ìˆìŠµë‹ˆë‹¤.**  \n",
    "\n",
    "LangGraphëŠ” **\"ì§€ì†ì  ì²´í¬í¬ì¸íŠ¸(Persistent Checkpointing)\"** ê¸°ëŠ¥ì„ í†µí•´ ì´ ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤.  \n",
    "\n",
    "ê·¸ë˜í”„ë¥¼ ì»´íŒŒì¼í•  ë•Œ checkpointingì„ í™œì„±í™”í•˜ê³  ê·¸ë˜í”„ë¥¼ í˜¸ì¶œí•  ë•Œ `thread_id`ë¥¼ ì œê³µí•˜ë©´, LangGraphê°€ ìë™ìœ¼ë¡œ ìƒíƒœ(state)ë¥¼ ì €ì¥í•˜ê³ , ë‹¤ìŒ ì‹¤í–‰ ì‹œ ì´ì „ ìƒíƒœë¥¼ ë³µì›í•©ë‹ˆë‹¤.  \n",
    "\n",
    "ì¦‰, **ë™ì¼í•œ `thread_id`** ë¥¼ ì‚¬ìš©í•˜ì—¬ ê·¸ë˜í”„ë¥¼ í˜¸ì¶œí•˜ë©´, ì´ì „ ëŒ€í™” ìƒíƒœë¥¼ ë¶ˆëŸ¬ì™€ì„œ ì´ì–´ì„œ ëŒ€í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccf74912-e1bd-4753-96f0-ad3398a9590a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1e5e51-8ec4-4b53-9154-c83b0097756a",
   "metadata": {},
   "source": [
    "ìš°ë¦¬ëŠ” í˜„ì¬ **ë©”ëª¨ë¦¬ë¥¼ í™œìš©í•˜ëŠ”(in-memory) ì²´í¬í¬ì¸í„°**ë¥¼ ì‚¬ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤.  \n",
    "\n",
    "ì´ ë°©ì‹ì€ íŠœí† ë¦¬ì–¼ í™˜ê²½ì—ì„œëŠ” í¸ë¦¬í•˜ì§€ë§Œ, ë°ì´í„°ê°€ ë©”ëª¨ë¦¬ì—ë§Œ ì €ì¥ë˜ë¯€ë¡œ ì˜êµ¬ì ì´ì§€ ì•ŠìŠµë‹ˆë‹¤. ì‹¤ì œ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” `SqliteSaver` ë˜ëŠ” `PostgresSaver`ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤(DB)ì™€ ì—°ê²°í•˜ëŠ” ê²ƒì´ ì¼ë°˜ì ì…ë‹ˆë‹¤.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb5e580e-25d9-4842-96ae-9a5622cce56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "ì•ˆë…•, ë‚œ ê¸¸ë™ì´ì•¼.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ì•ˆë…•, ê¸¸ë™ì•„! ì–´ë–»ê²Œ ë„ì™€ì¤„ê¹Œ?\n"
     ]
    }
   ],
   "source": [
    "agent_executor = create_react_agent(model, tools, checkpointer=memory)\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "\n",
    "input_message = {\"role\": \"user\", \"content\": \"ì•ˆë…•, ë‚œ ê¸¸ë™ì´ì•¼.\"}\n",
    "for step in agent_executor.stream(\n",
    "    {\"messages\": [input_message]}, config, stream_mode=\"values\"\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edffd5e-55d2-4fad-a54f-d56fac424b4d",
   "metadata": {},
   "source": [
    "### ë¬´í•œ loop ë¡œ Chatbot êµ¬í˜„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0a803cf-b3bc-41e0-a20a-6cf53c0ec29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  ì•ˆë…• ë‚œ ê¸¸ë™ì´ì•¼\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "ì•ˆë…• ë‚œ ê¸¸ë™ì´ì•¼\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ì•ˆë…•í•˜ì„¸ìš”, ê¸¸ë™ë‹˜! ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  ì§€ê¸ˆ ì„œìš¸ ë‚ ì”¨ëŠ”?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "ì§€ê¸ˆ ì„œìš¸ ë‚ ì”¨ëŠ”?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search (call_Pg09T7HOIOj4v0LD0lvNwjb1)\n",
      " Call ID: call_Pg09T7HOIOj4v0LD0lvNwjb1\n",
      "  Args:\n",
      "    query: ì„œìš¸ í˜„ì¬ ë‚ ì”¨\n",
      "    search_depth: basic\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"ì„œìš¸ í˜„ì¬ ë‚ ì”¨\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.accuweather.com/ko/kr/seoul/226081/current-weather/226081\", \"title\": \"ì„œìš¸íŠ¹ë³„ì‹œ, ì„œìš¸ì‹œ, ëŒ€í•œë¯¼êµ­ í˜„ì¬ ë‚ ì”¨ - AccuWeather\", \"content\": \"ì„œìš¸íŠ¹ë³„ì‹œ, ì„œìš¸ì‹œ, ëŒ€í•œë¯¼êµ­ í˜„ì¬ ë‚ ì”¨ | AccuWeather ì„œìš¸íŠ¹ë³„ì‹œ, ì„œìš¸ì‹œ ========== 65Â°F í˜„ì¬ ìœ„ì¹˜ ì‚¬ìš© ì„œìš¸íŠ¹ë³„ì‹œ ì„œìš¸ì‹œ 65Â° ì„œìš¸íŠ¹ë³„ì‹œ, ì„œìš¸ì‹œ ë‚ ì”¨ ì˜¤ëŠ˜ WinterCast ì§€ì—­ {stormName} ì¶”ì ê¸° ì‹œê°„ë³„ ì¼ë³„ ë ˆì´ë” MinuteCast ì›” ëŒ€ê¸°ì§ˆ ê±´ê°• ë° í™œë™ ì˜¤ëŠ˜ ì‹œê°„ë³„ ì¼ë³„ ë ˆì´ë” MinuteCast ì›” ëŒ€ê¸°ì§ˆ ê±´ê°• ë° í™œë™ í˜„ì¬ ê¸°ìƒ RealFeelÂ® 71Â° RealFeel Shadeâ„¢ 63Â° 71Â° 63Â° ìµœëŒ€ ìì™¸ì„  ì§€ìˆ˜ ì„œ 5mi/h 5mi/h 48Â° F 5mi RealFeelÂ® 81Â° RealFeel Shadeâ„¢ 73Â° ìµœëŒ€ ìì™¸ì„  ì§€ìˆ˜10 (ê±´ê°•ì— í•´ë¡œì›€) ë°”ëŒë‚¨ë‚¨ì„œ 8mi/h ê°•ìˆ˜ í™•ë¥ 0% ê°•ìˆ˜0.00in RealFeelÂ® 56Â° ë°”ëŒë‚¨ë™ 5mi/h ê°•ìˆ˜ í™•ë¥ 2% ê°•ìˆ˜0.00in ì¼ì¶œ AM 5:26 ì¼ëª° PM 7:31 ì¼ì¶œ PM 7:22 ì¼ëª° AM 5:14 77Â° 55Â° 70Â° 50Â° 71Â° 53Â° ### ì‹œê°„ë³„### ì¼ë³„### ì›” ì „ ì„¸ê³„ ì•„ì‹œì•„ ëŒ€í•œë¯¼êµ­ ì„œìš¸ì‹œ ì„œìš¸íŠ¹ë³„ì‹œ ë™ì‘êµ¬, ì„œìš¸ì‹œ ë§ˆí¬êµ¬, ì„œìš¸ì‹œ ì„œëŒ€ë¬¸êµ¬, ì„œìš¸ì‹œ\", \"score\": 0.8849276, \"raw_content\": null}, {\"url\": \"https://www.weather.go.kr/w/weather/forecast/short-term.do?stnId=109\", \"title\": \"ë‹¨ê¸°ì˜ˆë³´ - ì˜ˆë³´ - ë‚ ì”¨ - ê¸°ìƒì²­ ë‚ ì”¨ëˆ„ë¦¬\", \"content\": \"# ê¸°ìƒì²­ ë‚ ì”¨ëˆ„ë¦¬ ë³„í‘œë¥¼ ëˆ„ë¥´ë©´ ê´€ì‹¬ì§€ì—­ìœ¼ë¡œ ë“±ë¡ ë˜ëŠ” ì‚­ì œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤ â–¡ (ì¢…í•©) ì˜¤ëŠ˜ ì•„ì¹¨ê¹Œì§€ ì•ˆê°œ, ì˜¤ëŠ˜ ì˜¤í›„ ì„œìš¸.ê²½ê¸°ë‚´ë¥™ ì†Œë‚˜ê¸°, ëŒí’.ì²œë‘¥.ë²ˆê°œ.ìš°ë°• ìœ ì˜, ë‹¹ë¶„ê°„ ì„œí•´ì¤‘ë¶€í•´ìƒ ë°”ë‹¤ ì•ˆê°œ â—‹ (ì˜¤ëŠ˜, 29ì¼) ëŒ€ì²´ë¡œ ë§‘ê² ìœ¼ë‚˜, ì˜¤í›„(12~18ì‹œ)ì— êµ¬ë¦„ë§ê³  ì„œìš¸.ê²½ê¸°ë‚´ë¥™ ì†Œë‚˜ê¸°, ì„œí•´5ë„ ëŒ€ì²´ë¡œ ë§‘ìŒ â—‹ (ë‚´ì¼, 30ì¼) ëŒ€ì²´ë¡œ ë§‘ìŒâ—‹ (ëª¨ë ˆ, 31ì¼) ëŒ€ì²´ë¡œ ë§‘ìŒ, ì„œí•´5ë„ ëŒ€ì²´ë¡œ ë§‘ë‹¤ê°€ ì˜¤ì „ë¶€í„° êµ¬ë¦„ë§ìŒ â—‹ (ê¸€í”¼, 6ì›” 1ì¼) ëŒ€ì²´ë¡œ ë§‘ìŒ   \\\\ ì†Œë‚˜ê¸°ì— ì˜í•œ ì˜ˆìƒ ê°•ìˆ˜ëŸ‰(29ì¼ ì˜¤í›„)- ì„œìš¸.ê²½ê¸°ë‚´ë¥™: 5~20mm ë‹´ë‹¹ê´€ë¦¬ : ë³¸ì²­ ë¬¸ì˜ : ì „êµ­ êµ­ë²ˆì—†ì´ 131(ê¸°ìƒìƒë‹´ì „í™”, ìœ ë£Œ) ê¸°ìƒì²­ ì „êµ­ êµ­ë²ˆì—†ì´ ê¸°ìƒì½œì„¼í„° 131(ìœ ë£Œ) ê¸°ë³¸í™”ë©´: í˜„ì¬ë‚ ì”¨ ë° ì‹œê³„ì—´ ì •ë³´ê°€ í¬í•¨ëœ ì²«í™”ë©´   ë‚ ì”¨ ìš°ì„ : ì¡°íšŒì§€ì ì˜ í˜„ì¬ë‚ ì”¨ ë° ì‹œê³„ì—´ ì •ë³´ê°€ í¬í•¨ëœ ì²«í™”ë©´   ì „êµ­ ìš°ì„ : ì „êµ­ì§€ì—­ì˜ ë‚ ì”¨ë¥¼ ê°„ëµí•˜ê²Œ í‘œì¶œ 3ì‹œê°„ ê°„ê²©: ì‹œê°„ë³„ ì˜ˆë³´ë¥¼ 3ì‹œê°„ ê°„ê²©ìœ¼ë¡œ í‘œì¶œ   1ì‹œê°„ ê°„ê²©: ì‹œê°„ë³„ ì˜ˆë³´ë¥¼ 1ì‹œê°„ ê°„ê²©ìœ¼ë¡œ í‘œì¶œ ìµìŠ¤í”ŒëŸ¬ëŸ¬ ì„¤ì • ìŠ¤í¬ë¦°ìƒ·\", \"score\": 0.64639384, \"raw_content\": null}], \"response_time\": 1.24}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ì„œìš¸ì˜ í˜„ì¬ ë‚ ì”¨ëŠ” ì•½ 65Â°F (ì•½ 18Â°C)ë¡œ ë§‘ìœ¼ë©°, ë°”ëŒì€ ë‚¨ë‚¨ì„œ ë°©í–¥ìœ¼ë¡œ ì•½ 8ë§ˆì¼/hì…ë‹ˆë‹¤. ì˜¤ëŠ˜ì€ ëŒ€ì²´ë¡œ ë§‘ê³ , ê°•ìˆ˜ í™•ë¥ ì€ ë‚®ì•„ ë³´ì…ë‹ˆë‹¤. ë” ìì„¸í•œ ì •ë³´ëŠ” [ì—¬ê¸°](https://www.accuweather.com/ko/kr/seoul/226081/current-weather/226081)ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  ë‚´ ì´ë¦„ì´ ë­ì§€?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "ë‚´ ì´ë¦„ì´ ë­ì§€?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ê¸¸ë™ë‹˜ì´ì„¸ìš”! ë‹¤ë¥¸ ê¶ê¸ˆí•œ ì  ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ ì£¼ì„¸ìš”.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "# 'configurable' í‚¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶”ê°€ì ì¸ ì„¤ì • ê°’ì„ ì „ë‹¬í•©ë‹ˆë‹¤.\n",
    "# ì—¬ê¸°ì„œëŠ” 'thread_id'ë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¹ì • ëŒ€í™” ìŠ¤ë ˆë“œë¥¼ ì‹ë³„í•©ë‹ˆë‹¤.\n",
    "memory = MemorySaver()\n",
    "\n",
    "# ê·¸ë˜í”„ë¥¼ ë©”ëª¨ë¦¬ ì²´í¬í¬ì¸íŠ¸ì™€ í•¨ê»˜ ì»´íŒŒì¼í•©ë‹ˆë‹¤.\n",
    "agent_executor = create_react_agent(model, tools, checkpointer=memory)\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"abc345\"}}\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "\n",
    "    for step in agent_executor.stream({\"messages\": [user_input]}, config, stream_mode=\"values\"):\n",
    "        step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65e3e50-b633-4c19-b529-27eedaa4c0fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
