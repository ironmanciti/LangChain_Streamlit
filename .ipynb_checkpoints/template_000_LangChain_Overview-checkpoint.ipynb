{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eec79471",
   "metadata": {
    "id": "2TypDOiTPbjE"
   },
   "source": [
    "# LangChain 기능 소개\n",
    "\n",
    "- 1. 프롬프트 템플릿과 로더를 사용하여 체인 구성  \n",
    "- 2. Runnable과 LangChain 표현 언어  \n",
    "- 3. RAG 체인 구축  \n",
    "- 4. 체인이 달린 도구 사용  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b50664",
   "metadata": {
    "id": "TOUiSLMxPzZY"
   },
   "source": [
    "## LangChain 개요\n",
    "\n",
    "LangChain으로 개발된 애플리케이션은 일반적으로 세 가지 범주로 나뉩니다.\n",
    "\n",
    "- 챗봇 : LLM을 이용하여 보다 지능적인 마케팅, 고객 지원, 교육 상호작용 구현.\n",
    "- 검색 증강 생성(RAG) Q&A : 대용량 문서 요약, 데이터 분석, 외부 소스를 참조하여 코드 생성에 사용.\n",
    "- 에이전트 시스템은 다중 에이전트 설정과 인간 상호작용을 포함하며 복잡한 워크플로우를 위해 LangGraph를 활용. 공급망 관리 및 운영 최적화와 같은 분야에 적용 가능.\n",
    "\n",
    "LangChain은 자연어를 실행 가능한 프로그램으로 변환하는 파이프라인을 생성할 수 있게 합니다. 이러한 체인을 활용함으로써 사용자는 자연어를 입력하고 보고서, 분석 또는 컴퓨터 프로그램과 같은 출력을 받을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2959951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env 파일에서 API 키를 로드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d4d165",
   "metadata": {},
   "source": [
    "### 사용 가능한 LLM 목록 조회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9722838e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용 가능한 모델 목록을 가져옵니다.\n",
    "# 각 모델의 ID 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9290f7",
   "metadata": {
    "id": "XEi1gjmpW8ab"
   },
   "source": [
    "## LLM 연결\n",
    "\n",
    "OpenAI 및 Anthropic API에 연결합니다. 원하는 모델을 지정하여 ChatOpenAI 및 ChatAnthropic 클래스의 인스턴스를 만듭니다. llm_claude3 인스턴스를 사용하여 간단한 쿼리를 호출하여 설정을 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9b6664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d58d33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "796a6d6e",
   "metadata": {},
   "source": [
    "### Messages\n",
    "- AIMessage: AI(인공지능) 모델이 생성한 메시지를 나타냅니다.  \n",
    "예를 들어, AI 모델이 사용자의 질문에 대해 응답을 생성할 때 이 클래스가 사용됩니다.\n",
    "\n",
    "- HumanMessage: 사람(사용자)이 생성한 메시지를 나타냅니다.  \n",
    "사용자가 입력한 텍스트나 질문 등이 여기에 해당됩니다.\n",
    "\n",
    "- StemMessage: AI 행동을 프라이밍하기 위한 메시지.\n",
    "시스템 메시지는 일반적으로 일련의 입력 메시지 중 첫 번째로 전달됩니다. 일반적으로 대화의 흐름을 제어하거나 특정 지침을 제공하기 위해 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f337c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e76866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system과 human/user 메시지를 이용한 기본 요청"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e78705",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "126cf16e",
   "metadata": {},
   "source": [
    "### 수학 선생님"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb09586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc092231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e46f69b8",
   "metadata": {
    "id": "2fi6_NvW3MaE"
   },
   "source": [
    "##  1. 프롬프트 템플릿과 로더를 사용하여 체인 구성  \n",
    "\n",
    "- LLM에서의 Chain 은 Data Processing 에서의 Pipeline 과 유사한 개념"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12320d4d",
   "metadata": {
    "id": "G447ezl5X5ye"
   },
   "source": [
    "### 체인의 구성 요소 - Runnables\n",
    "- 프롬프트 : LLM의 응답을 안내하는 템플릿  \n",
    "- LLM 또는 채팅 모델 : 프롬프트에 따라 응답을 생성하는 엔진  \n",
    "- 출력 파서 : LLM의 출력을 파싱하는 도구  \n",
    "- 도구 : LLM이 API에서 추가 정보를 추출하거나 코드를 실행하여 LLM을 에이전트로 전환할 수 있게 해주는 확장 기능  \n",
    "- 일반 함수 : 서로 연결될 수 있는 추가적인 일반 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88fd52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple prompt template 생성\n",
    "# {topic} 변수에서 사용자의 query 가 대체된다.\n",
    "# prompt template 을 이용하여 prompt 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606eeeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe operator \"|\"\" 를 이용하여 하나 이상의 chain 을 결합"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1829136f",
   "metadata": {
    "id": "EJzXNZCnZRCr"
   },
   "source": [
    "### document loader 를 이용하여 script 요약\n",
    "더 고급 체인을 만들기 위해 LangChain을 사용하여 YouTube 비디오를 필사합니다. 먼저 YouTube Transcript API를 설치합니다. 그런 다음 LangChain의 커뮤니티 문서 로더에서 YouTube Loader를 가져옵니다. 로더에 비디오 URL을 전달하면 필사본을 추출할 수 있으며, 이는 문서 목록으로 반환됩니다. 원시 필사본을 얻으려면 이러한 문서에서 페이지 콘텐츠를 추출하거나 문서를 체인에 직접 전달하기만 하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42df4b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade --quiet youtube-transcript-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747d26b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain 커뮤니티에서 제공하는 Youtube Loader를 임포트\n",
    "# YoutubeLoader를 사용하여 유튜브 URL에서 로더를 생성\n",
    "# 비디오의 자막을 문서로 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31f7a95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd16cfdb",
   "metadata": {
    "id": "oEScwvtSck_C"
   },
   "source": [
    "이제, 대본이 주어진 YouTube 비디오를 요약하는 체인을 설정해 보겠습니다. 비디오 대본을 입력 변수로 프롬프트 템플릿에 주입한 다음 파이프 연산자를 사용하여 체인을 설정합니다. 비디오 대본으로 호출하면 원시 텍스트를 수동으로 추출하지 않고도 간결한 요약을 얻을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bd95fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전사된 내용을 chain에 사용합니다.\n",
    "# prompt template 생성\n",
    "# prompt instance 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9adb155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ebed94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ec70243",
   "metadata": {},
   "source": [
    "## 2. Runnable과 LangChain 표현 언어  \n",
    "\n",
    "- LCEL(LangChain Expression Language) 는 Runnables 를 chain 으로 구성하는 방법\n",
    "\n",
    "LCEL은 기본 구성 요소에서 복잡한 체인을 구축하는 것을 간소화합니다. 파이프 연산자(|)를 사용하여 다양한 구성 요소를 체인으로 연결하고 한 요소에서 다음 요소로 출력을 공급합니다. 이런 방식으로 구성된 체인의 간단한 예로는 모델과 출력 파서가 결합된 프롬프트가 있습니다.  이러한 구성 요소들을 runnables 라고 부릅니다.  \n",
    "\n",
    "`chain=prompt | model | output_parser`\n",
    "\n",
    "- Chain 구성  \n",
    "    - 체인에 대한 입력(일반적으로 사전)\n",
    "    - 입력은 프롬프트로 전송됩니다.\n",
    "    - 프롬프트 값은 LLM 또는 채팅 모델로 전송됩니다.\n",
    "    - Chatmodel이 채팅 메시지를 반환합니다.\n",
    "    - 파서는 채팅 메시지에서 문자열을 추출합니다.\n",
    "    - 문자열은 체인의 출력입니다\n",
    "\n",
    "- LangChain의 runnable 객체들:\n",
    "\n",
    "    - RunnableSequence : 여러 runnable 구성 요소를 연결하여 각 구성 요소가 입력을 처리하고 출력을 다음 구성 요소에 전달\n",
    "    - RunnableLambda : Python의 호출 가능한 요소(함수 등)를 실행 가능한 구성 요소로 바꿔서 체인으로 통합\n",
    "    - RunnablePassthrough : 입력을 변경하지 않고 통과시키거나 출력에 추가 키를 추가. placeholder 역할을 하거나 시퀀스에 유연하게 통합할 수 있다.\n",
    "    - RunnableParallel : 여러 개의 실행 파일을 동시에 실행하여 두 개의 체인이 동일한 입력에서 실행되지만 다른 출력을 반환하는 분기를 허용."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f482fa5",
   "metadata": {},
   "source": [
    "### Runnables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04334b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdd4786e",
   "metadata": {
    "id": "InN3aD1qGwmD"
   },
   "source": [
    "###  \"|\" 연산자를 이용하여 Runnable Sequence chain 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bcde59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78b5630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "216e1a82",
   "metadata": {
    "id": "j_VLKGZ1HO7d"
   },
   "source": [
    "### RunnableLambda 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afe5ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RunnableLambda를 사용하여 Python 함수를 체인에 삽입합니다.\n",
    "# 사용자 정의 람다 함수를 정의하고 이를 RunnableLambda에 래핑합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99b00a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054a7363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1a15cb4",
   "metadata": {},
   "source": [
    "## 3. 체인이 달린 도구 사용  \n",
    "\n",
    "- 도구는 에이전트, 체인 또는 대형 언어 모델(LLM)이 세상과 상호 작용할 수 있게 하는 인터페이스입니다.\n",
    "    - Python REPL, Wikipdedia, YouTube, Zapier, Gradio, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ecc3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade -q youtube_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d5d223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YouTubeSearchTool 인스턴스 생성\n",
    "# 아무 키워드로 유튜브 검색 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1843edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YouTube 도구를 LLM에 바인딩하여 parameter 정보를 알아냄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb188073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_with_tools 에서 parameter 정보를 알아낸다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf263968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e86634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_with_tools에서 추출된 인수로 \n",
    "# YouTubeSearchTool을 사용하여 유튜브 검색 실행한는 chain 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935323c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84ab908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65c47c6a",
   "metadata": {},
   "source": [
    "### Chains 종류\n",
    "\n",
    "**LangChain**을 사용하여 다양한 체인(Chain) 및 LLM(대규모 언어 모델) 기반 애플리케이션을 구축합니다.\n",
    "\n",
    "**1. Simple Chain (단일 체인)**  \n",
    "- 하나의 프롬프트를 통해 LLM(OpenAI)을 사용하여 텍스트를 생성합니다.  \n",
    "\n",
    "\n",
    "**2. Simple Sequential Chain (연속 체인)**  \n",
    "-  여러 LLM 호출을 연속적으로 수행하여 출력을 다음 입력으로 전달합니다.  \n",
    "\n",
    "**3. Document 요약 체인**  \n",
    "- **목적:** 텍스트 문서를 요약합니다.  \n",
    "\n",
    "**4. 텍스트를 Vector Store로 변환**  \n",
    "- **4.1 VectortstoreIndexCreator**   \n",
    "- **4.2 Chroma DB 사용**  \n",
    "\n",
    "**5. HTTP Request Chain (웹 요청 체인)**  \n",
    "- HTTP 요청을 통해 외부 웹 데이터에서 정보를 추출합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49239ec8",
   "metadata": {},
   "source": [
    "### 1. Simple Chain (단일 체인)\n",
    "- 가장 기본적인 유형의 체인\n",
    "- 입력 프롬프트를 수신하고 이를 사용하여 텍스트를 생성하는 역할을 담당하는 언어 모델(LLM) 하나만 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6370cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain = prompt.pipe(llm)\n",
    "# 입력 변수만 지정하여 체인을 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02736da7",
   "metadata": {},
   "source": [
    "### 2. Simple Sequential Chains (연속 체인)\n",
    "- Sequential Chain은 언어 모델에 대한 일련의 연속 호출 포함\n",
    "- 이 접근 방식은 한 호출에서 생성된 출력을 다른 호출의 입력으로 활용할 때 특히 유용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a4f799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e171974",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033336d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
