{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TypDOiTPbjE"
   },
   "source": [
    "# LangChain 기능 소개\n",
    "\n",
    "- 1. 프롬프트 템플릿과 로더를 사용하여 체인 구성  \n",
    "- 2. Runnable과 LangChain 표현 언어  \n",
    "- 3. RAG 체인 구축  \n",
    "- 4. 체인이 달린 도구 사용  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TOUiSLMxPzZY"
   },
   "source": [
    "## LangChain 개요\n",
    "\n",
    "LangChain으로 개발된 애플리케이션은 일반적으로 세 가지 범주로 나뉩니다.\n",
    "\n",
    "- 챗봇 : LLM을 이용하여 보다 지능적인 마케팅, 고객 지원, 교육 상호작용 구현.\n",
    "- 검색 증강 생성(RAG) Q&A : 대용량 문서 요약, 데이터 분석, 외부 소스를 참조하여 코드 생성에 사용.\n",
    "- 에이전트 시스템은 다중 에이전트 설정과 인간 상호작용을 포함하며 복잡한 워크플로우를 위해 LangGraph를 활용. 공급망 관리 및 운영 최적화와 같은 분야에 적용 가능.\n",
    "\n",
    "LangChain은 자연어를 실행 가능한 프로그램으로 변환하는 파이프라인을 생성할 수 있게 합니다. 이러한 체인을 활용함으로써 사용자는 자연어를 입력하고 보고서, 분석 또는 컴퓨터 프로그램과 같은 출력을 받을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U langchain-core\n",
    "# !pip install -U langchain-openai\n",
    "# !pip install -U langchain-community\n",
    "# !pip install -U langchain-experimental\n",
    "# !pip install -U langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FXRwb1YcsW1j",
    "outputId": "7e5cff59-b6f5-446d-e3cc-93891014f5c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# env 파일에서 API 키를 로드\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사용 가능한 LLM 목록 조회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gpt-4-0613', 'gpt-4', 'gpt-3.5-turbo', 'o4-mini-deep-research-2025-06-26', 'codex-mini-latest', 'gpt-4o-realtime-preview-2025-06-03', 'gpt-4o-audio-preview-2025-06-03', 'o4-mini-deep-research', 'davinci-002', 'babbage-002', 'gpt-3.5-turbo-instruct', 'gpt-3.5-turbo-instruct-0914', 'dall-e-3', 'dall-e-2', 'gpt-4-1106-preview', 'gpt-3.5-turbo-1106', 'tts-1-hd', 'tts-1-1106', 'tts-1-hd-1106', 'text-embedding-3-small', 'text-embedding-3-large', 'gpt-4-0125-preview', 'gpt-4-turbo-preview', 'gpt-3.5-turbo-0125', 'gpt-4-turbo', 'gpt-4-turbo-2024-04-09', 'gpt-4o', 'gpt-4o-2024-05-13', 'gpt-4o-mini-2024-07-18', 'gpt-4o-mini', 'gpt-4o-2024-08-06', 'chatgpt-4o-latest', 'o1-preview-2024-09-12', 'o1-preview', 'o1-mini-2024-09-12', 'o1-mini', 'gpt-4o-realtime-preview-2024-10-01', 'gpt-4o-audio-preview-2024-10-01', 'gpt-4o-audio-preview', 'gpt-4o-realtime-preview', 'omni-moderation-latest', 'omni-moderation-2024-09-26', 'gpt-4o-realtime-preview-2024-12-17', 'gpt-4o-audio-preview-2024-12-17', 'gpt-4o-mini-realtime-preview-2024-12-17', 'gpt-4o-mini-audio-preview-2024-12-17', 'o1-2024-12-17', 'o1', 'gpt-4o-mini-realtime-preview', 'gpt-4o-mini-audio-preview', 'computer-use-preview', 'o3-mini', 'o3-mini-2025-01-31', 'gpt-4o-2024-11-20', 'gpt-4.5-preview', 'gpt-4.5-preview-2025-02-27', 'computer-use-preview-2025-03-11', 'gpt-4o-search-preview-2025-03-11', 'gpt-4o-search-preview', 'gpt-4o-mini-search-preview-2025-03-11', 'gpt-4o-mini-search-preview', 'gpt-4o-transcribe', 'gpt-4o-mini-transcribe', 'o1-pro-2025-03-19', 'o1-pro', 'gpt-4o-mini-tts', 'o4-mini-2025-04-16', 'o4-mini', 'gpt-4.1-2025-04-14', 'gpt-4.1', 'gpt-4.1-mini-2025-04-14', 'gpt-4.1-mini', 'gpt-4.1-nano-2025-04-14', 'gpt-4.1-nano', 'gpt-image-1', 'gpt-3.5-turbo-16k', 'tts-1', 'whisper-1', 'text-embedding-ada-002']\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# 사용 가능한 모델 목록을 가져옵니다.\n",
    "models = openai.models.list()\n",
    "\n",
    "# 각 모델의 ID 출력\n",
    "print([model.id for model in models])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XEi1gjmpW8ab"
   },
   "source": [
    "## LLM 연결\n",
    "\n",
    "OpenAI 및 Anthropic API에 연결합니다. 원하는 모델을 지정하여 ChatOpenAI 및 ChatAnthropic 클래스의 인스턴스를 만듭니다. llm_claude3 인스턴스를 사용하여 간단한 쿼리를 호출하여 설정을 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jSY2uUq8ssCp"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-nano\")\n",
    "\n",
    "# from langchain_anthropic import ChatAnthropic\n",
    "# llm = ChatAnthropic(model=\"claude-3-5-haiku-20241022\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "id": "NFWMvMRitGX-",
    "outputId": "9eff0799-8467-4610-ee63-d3b945657364"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "물론입니다! LangChain은 자연어 처리(NLP) 분야에서 활용되는 개발 프레임워크로, 특히 대형 언어 모델(LLM)을 효과적으로 활용하는 애플리케이션을 개발하는 데 도움을 주는 도구입니다. \n",
      "\n",
      "주요 특징과 기능은 다음과 같습니다:\n",
      "\n",
      "1. **체인(Chains) 구성**: 여러 개의 자연어 처리 작업 또는 모델 호출을 순차적으로 연결하여 복잡한 작업을 수행할 수 있도록 도와줍니다. 예를 들어, 사용자 입력을 받아서 요약하고, 그 결과를 다시 분석하는 과정을 쉽게 구성할 수 있습니다.\n",
      "\n",
      "2. **프레임워크와 추상화**: 데이터 입력에서 출력까지의 과정을 표준화하고, 다양한 모델과 데이터 소스를 쉽게 연결할 수 있도록 구조화된 인터페이스를 제공합니다.\n",
      "\n",
      "3. **통합된 인터페이스**: OpenAI, Hugging Face 등 다양한 언어 모델 API와 통합되어 있어, 개발자가 특정 플랫폼에 종속되지 않고 여러 모델을 활용할 수 있게 합니다.\n",
      "\n",
      "4. **어플리케이션 개발 지원**: 챗봇, 질의응답 시스템, 가이드봇 등 다양한 자연어 기반 애플리케이션을 쉽게 개발할 수 있도록 도와주는 기능들을 포함하고 있습니다.\n",
      "\n",
      "5. **확장성과 유연성**: 사용자 맞춤형 기능 개발이 가능하며, 다양한 데이터 소스와 통합하여 복잡한 작업 흐름을 만들어낼 수 있습니다.\n",
      "\n",
      "요약하면, **LangChain은 대형 언어 모델을 활용한 애플리케이션 개발을 쉽고 체계적으로 만들어주는 프레임워크**로서, 개발자가 복잡한 자연어 처리 작업을 빠르게 설계하고 구현할 수 있도록 돕는 역할을 합니다.\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(\"한국어로 LangChain 에 대해서 설명해줘\").content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Messages\n",
    "- AIMessage: AI(인공지능) 모델이 생성한 메시지를 나타냅니다.  \n",
    "예를 들어, AI 모델이 사용자의 질문에 대해 응답을 생성할 때 이 클래스가 사용됩니다.\n",
    "\n",
    "- HumanMessage: 사람(사용자)이 생성한 메시지를 나타냅니다.  \n",
    "사용자가 입력한 텍스트나 질문 등이 여기에 해당됩니다.\n",
    "\n",
    "- StemMessage: AI 행동을 프라이밍하기 위한 메시지.\n",
    "시스템 메시지는 일반적으로 일련의 입력 메시지 중 첫 번째로 전달됩니다. 일반적으로 대화의 흐름을 제어하거나 특정 지침을 제공하기 위해 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "마치 다섯살 먹은 어린아이에게 설명하듯이 한국어로 쉽게 설명해 주세요.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "LangChain이 무엇인가요?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gYhhibXZSGTF",
    "outputId": "3d276aa8-39a2-4b85-b9aa-5bb43729783b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕! LangChain은 마치 레고 블록처럼 여러 가지 이야기나 정보를 잘 연결해서 사용하는 도구라고 생각하면 돼. 예를 들어, 넌 LEGO로 집을 만들 수도 있고, 자동차도 만들 수 있는데, LangChain은 여러 가지 정보를 잘 섞고 연결해서 똑똑한 로봇이 답도 잘 찾게 도와주는 도구야. 그래서 컴퓨터가 사람처럼 이야기하거나 문제를 해결하는 데 아주 좋아. 이해됐니?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 103, 'prompt_tokens': 43, 'total_tokens': 146, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_38343a2f8f', 'id': 'chatcmpl-BmtUizpoJjLfmisvrJSLhd7RwwzuC', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--80b65b0c-1203-413b-b619-e5bd0fa83b90-0', usage_metadata={'input_tokens': 43, 'output_tokens': 103, 'total_tokens': 146, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# system과 human/user 메시지를 이용한 기본 요청\n",
    "\n",
    "message = [\n",
    "    SystemMessage(content=system_prompt),\n",
    "    HumanMessage(content=user_prompt),\n",
    "]\n",
    "\n",
    "response = llm.invoke(message)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "AK7Xe8wnSQGa",
    "outputId": "c314481f-1ecb-4337-bf3c-08c274701b7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕! LangChain은 마치 레고 블록처럼 여러 가지 이야기나 정보를 잘 연결해서 사용하는 도구라고 생각하면 돼. 예를 들어, 넌 LEGO로 집을 만들 수도 있고, 자동차도 만들 수 있는데, LangChain은 여러 가지 정보를 잘 섞고 연결해서 똑똑한 로봇이 답도 잘 찾게 도와주는 도구야. 그래서 컴퓨터가 사람처럼 이야기하거나 문제를 해결하는 데 아주 좋아. 이해됐니?\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 수학 선생님"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81을 9로 나누면 9입니다.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"당신은  수학 문제를 잘 풀어주는 도움되는 assistant 입니다.\"),\n",
    "    HumanMessage(content=\"81을 9로 나누면 몇인가요?\")\n",
    "]\n",
    "\n",
    "result = llm.invoke(messages)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 곱하기 5는 50입니다.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"당신은  수학 문제를 잘 풀어주는 도움되는 assistant 입니다.\"),\n",
    "    HumanMessage(content=\"81을 9로 나누면 몇인가요?\"),\n",
    "    AIMessage(content=\"81을 9로 나누면 9입니다.\"),\n",
    "    HumanMessage(content=\"10 곱하기 5는 얼마인가요?\")\n",
    "]\n",
    "\n",
    "result = llm.invoke(messages)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2fi6_NvW3MaE"
   },
   "source": [
    "##  1. 프롬프트 템플릿과 로더를 사용하여 체인 구성  \n",
    "\n",
    "- LLM에서의 Chain 은 Data Processing 에서의 Pipeline 과 유사한 개념"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G447ezl5X5ye"
   },
   "source": [
    "### 체인의 구성 요소 - Runnables\n",
    "- 프롬프트 : LLM의 응답을 안내하는 템플릿  \n",
    "- LLM 또는 채팅 모델 : 프롬프트에 따라 응답을 생성하는 엔진  \n",
    "- 출력 파서 : LLM의 출력을 파싱하는 도구  \n",
    "- 도구 : LLM이 API에서 추가 정보를 추출하거나 코드를 실행하여 LLM을 에이전트로 전환할 수 있게 해주는 확장 기능  \n",
    "- 일반 함수 : 서로 연결될 수 있는 추가적인 일반 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Yt1j9kXR1h53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='\\n    당신은 AI 주제를 설명하는 데 도움이 되는 어시스턴트입니다. 다음 입력이 주어지면:\\n    {topic}\\n    주어진 주제에 대한 설명을 제공하세요.\\n')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# simple prompt template 생성\n",
    "# {topic} 변수에서 사용자의 query 가 대체된다.\n",
    "prompt_template = \"\"\"\n",
    "    당신은 AI 주제를 설명하는 데 도움이 되는 어시스턴트입니다. 다음 입력이 주어지면:\n",
    "    {topic}\n",
    "    주어진 주제에 대한 설명을 제공하세요.\n",
    "\"\"\"\n",
    "\n",
    "# prompt template 을 이용하여 prompt 생성 - old style\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=prompt_template,\n",
    ")\n",
    "\n",
    "# prompt template 을 이용하여 prompt 생성 - new style\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "id": "0vikrfE53yDk",
    "outputId": "adf40012-9025-4a1a-a591-da9fd5b4883c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain은 인공지능 및 자연어 처리(NLP) 분야에서 활용되는 프레임워크로, 대규모 언어 모델(LLMs)을 기반으로 하는 애플리케이션을 쉽게 구축하고 관리할 수 있도록 돕는 도구입니다. 이를 통해 개발자는 다양한 데이터 소스와 연동하여 복잡한 대화형 AI 시스템, 질문 답변 시스템, 챗봇 등을 효율적으로 개발할 수 있습니다. LangChain은 특히 자연어 이해, 지식베이스 연동, 텍스트 생성, 사용자 인터페이스 통합 등 다양한 기능을 지원하여 AI 응용 프로그램의 개발과 확장을 간소화하는 데 중점을 두고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# pipe operator \"|\"\" 를 이용하여 하나 이상의 chain 을 결합\n",
    "chain = prompt | llm\n",
    "\n",
    "print(chain.invoke({\"topic\": \"LangChain이 뭐예요?\"}).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Runnable과 LangChain 표현 언어  \n",
    "\n",
    "- LCEL(LangChain Expression Language) 는 Runnables 를 chain 으로 구성하는 방법\n",
    "\n",
    "LCEL은 기본 구성 요소에서 복잡한 체인을 구축하는 것을 간소화합니다. 파이프 연산자(|)를 사용하여 다양한 구성 요소를 체인으로 연결하고 한 요소에서 다음 요소로 출력을 공급합니다. 이런 방식으로 구성된 체인의 간단한 예로는 모델과 출력 파서가 결합된 프롬프트가 있습니다.  이러한 구성 요소들을 runnables 라고 부릅니다.  \n",
    "\n",
    "`chain=prompt | model | output_parser`\n",
    "\n",
    "- Chain 구성  \n",
    "    - 체인에 대한 입력(일반적으로 사전)\n",
    "    - 입력은 프롬프트로 전송됩니다.\n",
    "    - 프롬프트 값은 LLM 또는 채팅 모델로 전송됩니다.\n",
    "    - Chatmodel이 채팅 메시지를 반환합니다.\n",
    "    - 파서는 채팅 메시지에서 문자열을 추출합니다.\n",
    "    - 문자열은 체인의 출력입니다\n",
    "\n",
    "- LangChain의 runnable 객체들:\n",
    "\n",
    "    - RunnableSequence : 여러 runnable 구성 요소를 연결하여 각 구성 요소가 입력을 처리하고 출력을 다음 구성 요소에 전달\n",
    "    - RunnableLambda : Python의 호출 가능한 요소(함수 등)를 실행 가능한 구성 요소로 바꿔서 체인으로 통합\n",
    "    - RunnablePassthrough : 입력을 변경하지 않고 통과시키거나 출력에 추가 키를 추가. placeholder 역할을 하거나 시퀀스에 유연하게 통합할 수 있다.\n",
    "    - RunnableParallel : 여러 개의 실행 파일을 동시에 실행하여 두 개의 체인이 동일한 입력에서 실행되지만 다른 출력을 반환하는 분기를 허용."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runnables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "3s0DaSYO_W0Y"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\n    당신은 AI 개념을 요약하는 유용한 조수입니다.\\n    {context}\\n    context를 한국어로 요약해 주세요.\\n')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "summarize_prompt_template = \"\"\"\n",
    "    당신은 AI 개념을 요약하는 유용한 조수입니다.\n",
    "    {context}\n",
    "    context를 한국어로 요약해 주세요.\n",
    "\"\"\"\n",
    "\n",
    "summarize_prompt = PromptTemplate.from_template(summarize_prompt_template)\n",
    "summarize_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "InN3aD1qGwmD"
   },
   "source": [
    "###  \"|\" 연산자를 이용하여 Runnable Sequence chain 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P0cahXhesl-E",
    "outputId": "eed661f4-9190-4da5-f8df-0139d0df7b64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = summarize_prompt | llm | output_parser\n",
    "\n",
    "print(type(chain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "id": "WpJAZmpOsjHA",
    "outputId": "147f9a53-6d84-4d3c-cae6-4322635e23f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain은 인공지능 기반 애플리케이션 개발을 돕는 오픈소스 프레임워크입니다. 특히, 자연어 처리(NLP) 모델과 다양한 도구, 데이터 소스를 연결하여 복잡한 작업을 수행할 수 있도록 설계되었습니다. 이를 통해 개발자는 대화형 에이전트, 챗봇, 자동화된 워크플로우 등을 보다 쉽게 구축할 수 있습니다. 핵심 기능으로는 자연어 이해, 기억, 도구 호출, 외부 API 연동 등이 있으며, 모듈화된 구조로 유연한 확장성이 특징입니다. 한국어를 포함한 다양한 언어와 데이터 소스를 지원하며, AI 애플리케이션 개발을 빠르고 효율적으로 만들어줍니다.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"context\": \"LangChain 에 대해 설명해 줘.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_VLKGZ1HO7d"
   },
   "source": [
    "### RunnableLambda 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oI9MZ0sasxQf",
    "outputId": "c5356d5c-6811-43af-9bfb-31fe88e2638e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "<class 'langchain_core.runnables.base.RunnableLambda'>\n",
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "# RunnableLambda를 사용하여 Python 함수를 체인에 삽입합니다.\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "summarize_chain = summarize_prompt | llm | output_parser\n",
    "print(type(summarize_chain))\n",
    "\n",
    "# 사용자 정의 람다 함수를 정의하고 이를 RunnableLambda에 래핑합니다.\n",
    "length_lambda = RunnableLambda(lambda summary: f\"요약된 길이: {len(summary)} 글자\")\n",
    "print(type(length_lambda))\n",
    "\n",
    "lambda_chain = summarize_chain | length_lambda\n",
    "print(type(lambda_chain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "TAa1W6iVHLnq",
    "outputId": "5b181616-a4f7-49a1-b807-9795fc389b9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'요약된 길이: 290 글자'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_chain.invoke({\"context\": \"LangChain 에 대해 설명해 줘\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DhIbYeOgIYyi",
    "outputId": "6ee972ca-751b-4b86-a8cd-fefe6fbe8c41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context'] input_types={} partial_variables={} template='\\n    당신은 AI 개념을 요약하는 유용한 조수입니다.\\n    {context}\\n    context를 한국어로 요약해 주세요.\\n'\n",
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000001F3D63A7150> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001F3D63BC310> root_client=<openai.OpenAI object at 0x000001F3D63A6E50> root_async_client=<openai.AsyncOpenAI object at 0x000001F3D63A7DD0> model_name='gpt-4.1-nano' model_kwargs={} openai_api_key=SecretStr('**********')\n",
      "\n",
      "RunnableLambda(lambda summary: f'요약된 길이: {len(summary)} 글자')\n"
     ]
    }
   ],
   "source": [
    "for step in lambda_chain.steps:\n",
    "    print(step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 체인이 달린 도구 사용  \n",
    "\n",
    "- 도구는 에이전트, 체인 또는 대형 언어 모델(LLM)이 세상과 상호 작용할 수 있게 하는 인터페이스입니다.\n",
    "    - Python REPL, Wikipdedia, YouTube, Zapier, Gradio, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "RkuqKhVpyKxm"
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade -q youtube_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ZF5O2LeB-vD",
    "outputId": "86cbdc7a-8466-410b-864b-7c67acc519db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.youtube.com/watch?v=QWG499BvCbM&pp=ygUP7L2U65Sp7ZWY64qUIEFJ', 'https://www.youtube.com/watch?v=1kPVTY0M4hE&pp=ygUP7L2U65Sp7ZWY64qUIEFJ']\n"
     ]
    }
   ],
   "source": [
    "# 유튜브를 검색하는 함수\n",
    "from langchain_community.tools import YouTubeSearchTool\n",
    "\n",
    "# YouTubeSearchTool 인스턴스 생성\n",
    "youtube_tool = YouTubeSearchTool()\n",
    "\n",
    "# 아무 키워드로 유튜브 검색 실행 --> 함수가 잘 실행되는 것 확인.\n",
    "results = youtube_tool.run(\"코딩하는 AI\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- YouTubeSearchTool 함수를 LLM 에 넘겨 주고 LLM이 이 함수를 이용하여 세상과 상호 작용 (유튜브 검색)할 수 있도록 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S5BZ28LTAtul",
    "outputId": "62f913a7-6b6c-415c-d494-4ad127a6a18d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_URJJnEeDsVE8X6QFHvkClTdc', 'function': {'arguments': '{\"query\":\"코딩하는 AI\"}', 'name': 'youtube_search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 94, 'total_tokens': 111, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_38343a2f8f', 'id': 'chatcmpl-BmtVE6b5ToLiAa1wxKStG3UsDEeDV', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--41db4e08-c323-4b68-a05c-ef0a3aad36dc-0', tool_calls=[{'name': 'youtube_search', 'args': {'query': '코딩하는 AI'}, 'id': 'call_URJJnEeDsVE8X6QFHvkClTdc', 'type': 'tool_call'}], usage_metadata={'input_tokens': 94, 'output_tokens': 17, 'total_tokens': 111, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1단계: LLM이 어떤 tool과 args를 쓸지 판단할 수 있도록 함\n",
    "# YouTube 도구를 LLM에 바인딩 --> OpenAI API 의 'tools=' parameter에 함수명과 \n",
    "# 함수 호출에 필요한 parameter 정보 전달\n",
    "llm_with_tools = llm.bind_tools([youtube_tool])\n",
    "\n",
    "msg = llm_with_tools.invoke(\"코딩하는 AI\")\n",
    "msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'youtube_search',\n",
       "  'args': {'query': '코딩하는 AI'},\n",
       "  'id': 'call_URJJnEeDsVE8X6QFHvkClTdc',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# msg에서 OpenAI LLM이 구성해준 함수호출 parameter 발췌\n",
    "msg.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': '코딩하는 AI'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YouTubeSearchTool 호출에 필요한 parameter\n",
    "msg.tool_calls[0][\"args\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001F3D63A7150>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001F3D63BC310>, root_client=<openai.OpenAI object at 0x000001F3D63A6E50>, root_async_client=<openai.AsyncOpenAI object at 0x000001F3D63A7DD0>, model_name='gpt-4.1-nano', model_kwargs={}, openai_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'youtube_search', 'description': 'search for youtube videos associated with a person. the input to this tool should be a comma separated list, the first part contains a person name and the second a number that is the maximum number of video results to return aka num_results. the second part is optional', 'parameters': {'properties': {'query': {'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| RunnableLambda(lambda x: x.tool_calls[0]['args'])\n",
       "| YouTubeSearchTool()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2단계: Tool call → 파라미터 추출 → Tool 실행\n",
    "# llm_with_tools에서 추출된 인수로 YouTubeSearchTool을 사용하여 유튜브 검색 실행하는 chain 생성\n",
    "chain = llm_with_tools | (lambda x: x.tool_calls[0][\"args\"]) | youtube_tool\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['https://www.youtube.com/watch?v=1kPVTY0M4hE&pp=ygUP7L2U65Sp7ZWY64qUIEFJ', 'https://www.youtube.com/watch?v=QWG499BvCbM&pp=ygUP7L2U65Sp7ZWY64qUIEFJ']\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke('코딩하는 AI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.youtube.com/watch?v=QWG499BvCbM&pp=ygUP7L2U65Sp7ZWY64qUIEFJ',\n",
       " 'https://www.youtube.com/watch?v=1kPVTY0M4hE&pp=ygUP7L2U65Sp7ZWY64qUIEFJ']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "response = chain.invoke(\"코딩하는 AI\")\n",
    "ast.literal_eval(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chains 종류\n",
    "\n",
    "**LangChain**을 사용하여 다양한 체인(Chain) 및 LLM(대규모 언어 모델) 기반 애플리케이션을 구축합니다.\n",
    "\n",
    "**1. Simple Chain (단일 체인)**  \n",
    "- 하나의 프롬프트를 통해 LLM(OpenAI)을 사용하여 텍스트를 생성합니다.  \n",
    "\n",
    "\n",
    "**2. Simple Sequential Chain (연속 체인)**  \n",
    "-  여러 LLM 호출을 연속적으로 수행하여 출력을 다음 입력으로 전달합니다.  \n",
    "\n",
    "**3. Document 요약 체인**  \n",
    "- **목적:** 텍스트 문서를 요약합니다.  \n",
    "\n",
    "**4. 텍스트를 Vector Store로 변환**  \n",
    "- **4.1 VectortstoreIndexCreator**   \n",
    "- **4.2 Chroma DB 사용**  \n",
    "\n",
    "**5. HTTP Request Chain (웹 요청 체인)**  \n",
    "- HTTP 요청을 통해 외부 웹 데이터에서 정보를 추출합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Simple Chain (단일 체인)\n",
    "- 가장 기본적인 유형의 체인\n",
    "- 입력 프롬프트를 수신하고 이를 사용하여 텍스트를 생성하는 역할을 담당하는 언어 모델(LLM) 하나만 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국에서 꼭 가볼 만한 추천 여행지는 정말 다양하지만, 몇 가지 대표적인 곳을 소개해드릴게요:\n",
      "\n",
      "1. 서울특별시\n",
      "- 경복궁과 창덕궁 등 궁궐: 한국의 역사와 전통을 느낄 수 있는 곳\n",
      "- 북촌 한옥마을: 전통 한옥과 문화거리\n",
      "- 명동과 강남: 쇼핑과 현대적 도시 분위기 체험\n",
      "- 남산타워(Namsan Seoul Tower): 서울 시내 전망\n",
      "\n",
      "2. 부산광역시\n",
      "- 해운대 해수욕장: 아름다운 해변과 야경\n",
      "- 감천문화마을: 컬러풀한 벽화와 독특한 가옥들\n",
      "- 자갈치시장: 신선한 해산물과 활기찬 시장 풍경\n",
      "\n",
      "3. 제주도\n",
      "- 한라산 등반 또는 트레킹\n",
      "- 성산일출봉: 일출 감상 명소\n",
      "- 제주 올레길: 자연과 함께하는 걷기 여행\n",
      "- 우도, 만장굴, 제주 민속촌 등 관광지 다수\n",
      "\n",
      "4. 경주\n",
      "- 석굴암과 불국사: 신라시대 유적지와 문화유산\n",
      "- 첨성대와 경주 양동마을: 역사적 멋과 전통 체험\n",
      "\n",
      "5. 강원도\n",
      "- 설악산 국립공원: 등산과 자연경관 감상\n",
      "- 강릉 경포대: 해변과 일출 풍경\n",
      "\n",
      "이 외에도 한국 곳곳에는 독특하고 아름다운 명소들이 많으니 여행 목적과 관심사에 따라 선택하시면 좋을 것 같습니다!\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate.from_template(\"{place}에서 가장 가 볼만한 곳은?\")\n",
    "\n",
    "chain = prompt | llm\n",
    "# chain = prompt.pipe(llm)\n",
    "\n",
    "# 입력 변수만 지정하여 체인을 실행\n",
    "print(chain.invoke(\"한국\").content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Simple Sequential Chains (연속 체인)\n",
    "- Sequential Chain은 언어 모델에 대한 일련의 연속 호출 포함\n",
    "- 이 접근 방식은 한 호출에서 생성된 출력을 다른 호출의 입력으로 활용할 때 특히 유용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['place'], input_types={}, partial_variables={}, template='{place}에서 방문하기 가장 좋은 장소 5곳을 추천해주세요\\n\\n응답:\\n')\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001F3D63A7150>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001F3D63BC310>, root_client=<openai.OpenAI object at 0x000001F3D63A6E50>, root_async_client=<openai.AsyncOpenAI object at 0x000001F3D63A7DD0>, model_name='gpt-4.1-nano', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| PromptTemplate(input_variables=['budget'], input_types={}, partial_variables={}, template='장소 목록이 주어지면, 모든 장소를 방문하는 데 드는 비용과 방문에 필요한 날짜를 현지 통화로 추산해 주십시오. \\n그리고 나서 예산 {budget}과 비교하여 충분한지, 부족한지 계산해 주세요.\\n\\n응답:\\n')\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001F3D63A7150>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001F3D63BC310>, root_client=<openai.OpenAI object at 0x000001F3D63A6E50>, root_async_client=<openai.AsyncOpenAI object at 0x000001F3D63A7DD0>, model_name='gpt-4.1-nano', model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template_1 = \"\"\"{place}에서 방문하기 가장 좋은 장소 5곳을 추천해주세요\n",
    "\n",
    "응답:\n",
    "\"\"\"\n",
    "\n",
    "prompt1 = PromptTemplate.from_template(template_1)\n",
    "\n",
    "chain1 = prompt1 | llm\n",
    "\n",
    "template_2 = \"\"\"장소 목록이 주어지면, 모든 장소를 방문하는 데 드는 비용과 방문에 필요한 날짜를 현지 통화로 추산해 주십시오. \n",
    "그리고 나서 예산 {budget}과 비교하여 충분한지, 부족한지 계산해 주세요.\n",
    "\n",
    "응답:\n",
    "\"\"\"\n",
    "\n",
    "prompt2 = PromptTemplate.from_template(template_2)\n",
    "\n",
    "chain2 = prompt2 | llm\n",
    "\n",
    "final_chain = chain1 | chain2\n",
    "final_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제공된 장소 목록과 여행 내용이 약 391 토큰으로, 일반적으로 충분한 상세 정보를 담고 있다고 볼 수 있습니다. \n",
      "\n",
      "구체적으로:\n",
      "- 장소별 설명과 추천 이유를 담고 있으며,\n",
      "- 예상 비용과 날짜를 추산하는 요청에 대해 구체적인 숫자나 계획이 포함되어 있지 않지만,\n",
      "- 텍스트 내용은 여행 추천과 장소 설명 위주로 이뤄져 있습니다.\n",
      "\n",
      "이 경우, 비용과 날짜 예상값을 구체적으로 제공하려면 추가 데이터(환율, 평균 숙박비, 교통비, 입장료 등)가 필요하겠지만, 요청하신 '충분한지 여부' 판단 기준으로 보면 지금 제공된 내용은 여행 계획의 세부 비용 산출물보다 참고용 추천 안내에 가깝습니다.\n",
      "\n",
      "요약하면:\n",
      "- 현재 텍스트 길이와 내용은 충분하나, '비용과 날짜 예상'에 대한 수치 정보는 포함되어 있지 않으므로, 그 부분은 별도 자료 또는 계산이 필요합니다.\n",
      "- 만약 비용과 날짜에 대한 구체적인 산출이 필요하다면, 관련 데이터를 추가 제공하거나 계산을 진행해야 합니다.\n",
      "\n",
      "따라서:  \n",
      "이 텍스트는 추천 장소 소개에 적합하며, 비용과 날짜 예상 산출을 위해선 추가 정보가 더 필요하니, 지금 상태로는 '충분하다'기보단 '보완이 필요하다'고 할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "review = final_chain.invoke({\"place\": \"한국\", \"budget\": \"1,000,000\"})\n",
    "print(review.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
