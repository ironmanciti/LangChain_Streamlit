{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U8DZpMrEawNo"
   },
   "source": [
    "# Chatbot 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7sYz4BNOawNp"
   },
   "source": [
    "LangChain v0.3 부터는 memory 사용을 위해 LangGraph 지속성(LangGraph Persistence)을 사용하는 것이 권장됩니다.\n",
    "\n",
    "이전 버전에서 이미 RunnableWithMessageHistory 또는 BaseChatMessageHistory에 의존하고 있는 코드라면 아무 변경도 필요하지 않습니다. 이 기능은 간단한 채팅 애플리케이션에서 계속 사용할 수 있으며, RunnableWithMessageHistory를 사용하는 코드는 기대한 대로 계속 작동할 것입니다.\n",
    "\n",
    "### 개요 (Overview)\n",
    "LLM을 활용한 챗봇 설계 및 구현 예제를 살펴보겠습니다.\n",
    "이 챗봇은 대화를 나누고 이전 상호작용을 기억할 수 있습니다.\n",
    "\n",
    "이 챗봇은 언어 모델만 사용하여 대화를 진행합니다.\n",
    "다음과 같은 관련 개념도 확인할 수 있습니다:\n",
    "\n",
    "- Conversational RAG: 외부 데이터 소스를 활용한 챗봇\n",
    "- 에이전트(Agents): 액션을 수행할 수 있는 챗봇\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hs-phAmrn_nU",
    "outputId": "176c1c85-5efd-4ce2-b57a-b417ca8d4422"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "FIGxlnudejjY"
   },
   "outputs": [],
   "source": [
    "# LangSmith 추적 설정 활성화\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WDfJAe73awNq"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7YhZjWjbawNq"
   },
   "source": [
    "먼저 모델을 직접 사용해 봅니다. `ChatModel`은 LangChain의 **\"Runnable\"** 인스턴스이며, 이는 표준화된 인터페이스를 통해 상호작용할 수 있음을 의미합니다.  \n",
    "\n",
    "모델을 간단하게 호출하려면 `.invoke` 메서드에 **메시지 목록**을 전달하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p3dedQyCawNq",
    "outputId": "07ace5b9-bb79-4179-92ed-12f206a9edb8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕, 길동! 만나서 반가워. 어떻게 지내고 있어?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "response = model.invoke([HumanMessage(content=\"안녕! 나는 길동이야.\")])\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-98EDJ_mawNr"
   },
   "source": [
    "모델 자체는 **상태(state)** 라는 개념을 가지고 있지 않습니다. 예를 들어, 후속 질문을 하면:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H2eCUUVUawNr",
    "outputId": "5cf40659-9434-45a2-e1f6-ea816a157cb1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'죄송하지만, 당신의 이름을 알 수 있는 정보가 없습니다. 이름을 알려주시면 그에 맞춰 대화할 수 있습니다!'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model.invoke([HumanMessage(content=\"내 이름이 뭐라고 했지?\")])\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5_UtWJJkawNs",
    "outputId": "8a4039b1-70ab-43f7-f392-3e8fd01dcdfd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'당신의 이름은 길동이세요!'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "response = model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"안녕! 나는 길동이야.\"),\n",
    "        AIMessage(content=\"안녕하세요, 길동님. 무엇을 도와 드릴까요?\"),\n",
    "        HumanMessage(content=\"내 이름이 뭐라고 했지?\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6GsjjivawNs"
   },
   "source": [
    "<br>\n",
    "이제 좋은 응답을 받는 것을 확인할 수 있습니다!  \n",
    "\n",
    "이것이 챗봇이 **대화형 상호작용**을 할 수 있는 기본 아이디어입니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UYWFZWBuawNs"
   },
   "source": [
    "## **메시지 지속성 (Message Persistence)**  \n",
    "\n",
    "**LangGraph**는 **내장된 지속성 계층(persistence layer)** 을 구현하여 **여러 번의 대화(turns)** 를 지원하는 챗 애플리케이션에 이상적입니다.  \n",
    "\n",
    "챗 모델을 간단한 LangGraph 애플리케이션으로 감싸면 **메시지 기록을 자동으로 저장(persist)** 할 수 있어, **다중 턴(multi-turn)** 애플리케이션 개발이 훨씬 더 간편해집니다.  \n",
    "\n",
    "LangGraph에는 **간단한 인메모리 체크포인터(in-memory checkpointer)** 가 포함되어 있으며, 아래 예제에서 이를 사용합니다.  \n",
    "\n",
    "### 1) 가장 기본적인 형태의 LLM 그래프 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PPQ50D82awNs"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x0000029AB12E63A0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver  # 인메모리 체크포인트를 위한 MemorySaver 임포트\n",
    "from langgraph.graph import START, MessagesState, StateGraph  # 그래프 시작 지점, 메시지 상태, 그래프 정의를 위한 클래스 임포트\n",
    "\n",
    "# 메시지 상태(MessagesState)를 상태 스키마(state_schema)로 사용하여 워크플로우를 정의\n",
    "# MessagesState는 messages 필드 하나만 포함하는 TypedDict 구조\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "# 모델을 호출하는 함수 정의\n",
    "def call_model(state: MessagesState):\n",
    "    \"\"\"\n",
    "    LLM(언어 모델)에 메시지를 전달하고 응답을 받습니다.\n",
    "    Args - state (MessagesState): 현재 대화 상태 (이전 메시지 포함)\n",
    "    Returns - dict: 모델의 응답을 포함한 새로운 상태 \n",
    "    \"\"\"\n",
    "    response = model.invoke(state[\"messages\"])  # 상태에서 메시지를 추출하고 모델에 전달\n",
    "    return {\"messages\": response}               # 응답을 딕셔너리 형태로 반환\n",
    "\n",
    "\n",
    "# 그래프 노드 및 엣지 설정\n",
    "# START 지점에서 \"model\" 노드로 이동하도록 엣지를 추가합니다.\n",
    "workflow.add_edge(START, \"model\")\n",
    "\n",
    "# \"model\" 노드에 call_model 함수를 연결합니다.\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "# 메모리 추가 (메시지 기록 저장)\n",
    "memory = MemorySaver()  # 인메모리 체크포인트 저장소 생성\n",
    "\n",
    "# 워크플로우를 메모리 체크포인트와 함께 컴파일합니다.\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zul9zuiGawNt"
   },
   "source": [
    "이제 매번 `runnable` 객체에 전달할 **`config`** 를 생성해야 합니다.  \n",
    "\n",
    "이 **`config`** 에는 입력에 직접 포함되지는 않지만 유용한 정보가 포함됩니다.  이번 경우, **`thread_id`** 를 포함할 것 입니다.  \n",
    "\n",
    "다음과 같은 형태여야 합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "SlIcRDAiawNt"
   },
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KBNmUJh1awNt"
   },
   "source": [
    "이렇게 하면 하나의 애플리케이션에서 **여러 대화 스레드(thread)**를 지원할 수 있습니다.  \n",
    "\n",
    "여러 사용자가 애플리케이션을 동시에 사용할 때 흔히 필요한 기능입니다.  \n",
    "\n",
    "이제 애플리케이션을 호출할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sOO2WFSMawNt",
    "outputId": "adf33b41-548a-4298-96c7-effcc0c55860"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "안녕하세요, 길동님! 만나서 반갑습니다. 어떻게 도와드릴까요?\n"
     ]
    }
   ],
   "source": [
    "query = \"안녕! 내 이름은 길동이야.\"\n",
    "\n",
    "# 입력 메시지를 리스트 형태로 정의\n",
    "# 이는 대화의 첫 번째 메시지가 됩니다.\n",
    "input_messages = [HumanMessage(query)]\n",
    "\n",
    "# 'app.invoke'를 사용하여 애플리케이션을 호출\n",
    "# 첫 번째 매개변수: 입력 메시지\n",
    "# 두 번째 매개변수: 추가적인 설정(config) - 예: thread_id 등\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "\n",
    "# 상태(state)에 있는 모든 메시지 중 마지막 메시지 출력\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CZmp-CtmawNt",
    "outputId": "5b17bfc7-2719-4354-8e7f-fb342de75807"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "길동님이라고 하셨습니다! 맞나요?\n"
     ]
    }
   ],
   "source": [
    "query = \"내 이름이 뭐라고 했지?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pGnh-twbawNt"
   },
   "source": [
    "<br>\n",
    "이제 우리의 챗봇은 우리에 대한 정보를 기억합니다.  \n",
    "\n",
    "`config`에서 다른 **`thread_id`** 를 참조하도록 변경하면, 챗봇이 **새로운 대화**를 시작하는 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kOd6F-FmawNt",
    "outputId": "4be8d3e1-ae7f-4e3e-e44b-dd62ac3dcfb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "죄송하지만, 당신의 이름을 알 수 있는 정보가 없습니다. 제가 도와드릴 수 있는 다른 것이 있을까요?\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc234\"}}\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6FwatDsDawNt"
   },
   "source": [
    "그러나 우리는 항상 **원래의 대화로 돌아갈 수 있습니다** (데이터베이스에 대화를 **저장(persisting)** 하고 있기 때문입니다)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WhXNuvsEawNt",
    "outputId": "4aafe86c-61e4-438c-e6b9-e5559af6cbea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "길동님이라고 하셨습니다. 다른 질문이나 필요하신 것이 있나요?\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ImOJzRsQawNu"
   },
   "source": [
    "<br>\n",
    "이렇게 하면 챗봇이 여러 사용자와 동시에 대화를 할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IVsbpFCCawNu"
   },
   "source": [
    "지금까지 우리는 모델 주위에 간단한 **지속성 계층(persistence layer, 메모리)** 을 추가한 것에 불과합니다. 이제 **프롬프트 템플릿(prompt template)** 을 추가하여 챗봇을 더 복잡하고 개인화된 형태로 만들어 봅시다.\n",
    "\n",
    "---\n",
    "\n",
    "### 2) 프롬프트 템플릿(Prompt Templates)을 사용하여 LLM 호출 최적화\n",
    "\n",
    "**프롬프트 템플릿** 은 **원시 사용자 입력(raw user input)** 을 LLM이 처리할 수 있는 형식으로 변환하는 데 도움을 줍니다.   \n",
    "\n",
    "1. 먼저, **시스템 메시지(system message)** 를 추가하여 **사용자 정의 지침(custom instructions)** 을 포함시킵니다. (여전히 메시지를 입력으로 사용)  \n",
    "2. 다음으로, 메시지 외에 **더 많은 입력 정보** 를 추가합니다.  \n",
    "\n",
    "#### **시스템 메시지(System Message) 추가하기**\n",
    "\n",
    "시스템 메시지를 추가하기 위해 **`ChatPromptTemplate`** 을 생성합니다. 여기서는 메시지 전달을 위해 **`MessagesPlaceholder`** 를 사용하겠습니다.  \n",
    "\n",
    "이렇게 하면 LLM에 전달되는 입력이 더 구조화되고, 챗봇의 동작을 더 정교하게 제어할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "wK8gV0KPawNu"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# LLM이 사용자 입력을 더 잘 처리할 수 있도록 프롬프트 템플릿을 설정합니다.\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        # LLM의 동작 방식을 정의하는 지침\n",
    "        (\n",
    "            \"system\",\n",
    "            \"당신은 친구 처럼 말합니다. 모든 질문에 최선을 다해 대답하세요.\",\n",
    "        ),\n",
    "\n",
    "        # Messages Placeholder - 이전 대화 메시지들을 전달합\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9UytXq1UawNu"
   },
   "source": [
    "이제 이 템플릿을 통합하여 애플리케이션을 업데이트할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "BG4R2IZDawNu"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x0000029AB3F51250>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import START, StateGraph, MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# MessagesState를 상태 스키마로 사용하여 워크플로우를 정의합니다.\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "# 모델 호출 함수 정의\n",
    "def call_model(state: MessagesState):\n",
    "    prompt = prompt_template.invoke(state)   # 현재 상태(state)를 기반으로 프롬프트를 생성\n",
    "    response = model.invoke(prompt)        # 생성된 프롬프트를 LLM에 전달하여 응답 생성\n",
    "    return {\"messages\": response}   # 모델의 응답을 딕셔너리 형태로 반환\n",
    "\n",
    "# START에서 \"model\" 노드로 이동하도록 엣지 정의\n",
    "workflow.add_edge(START, \"model\")\n",
    "\n",
    "# \"model\" 노드에 call_model 함수를 연결\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "# MemorySaver를 사용하여 상태 및 메시지 기록을 저장합니다.\n",
    "memory = MemorySaver()\n",
    "\n",
    "# 그래프를 메모리 체크포인트와 함께 컴파일합니다.\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-7IBeVsawNu"
   },
   "source": [
    "같은 방식으로 응용 프로그램을 호출합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OL2lsrmqawNu",
    "outputId": "03b80ea7-4f24-406d-e1fb-08838bffe9b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "안녕! 어떻게 지내? 뭐 도와줄 일이 있어?\n"
     ]
    }
   ],
   "source": [
    "# 'configurable' 키를 사용하여 추가적인 설정 값을 전달합니다.\n",
    "# 여기서는 'thread_id'를 사용하여 특정 대화 스레드를 식별합니다.\n",
    "config = {\"configurable\": {\"thread_id\": \"abc345\"}}\n",
    "\n",
    "query = \"안녕.\"\n",
    "\n",
    "# 메시지 목록에 사용자 메시지 추가\n",
    "input_messages = [HumanMessage(query)]\n",
    "\n",
    "# 애플리케이션 호출\n",
    "# 메시지 상태(State), 설정(config) 전달\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qc4lo7HvawNu",
    "outputId": "52475e28-acdb-4651-aa2b-2b711bf9ca17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "아쉽게도 너의 이름을 모르겠어. 너의 이름이 뭐야? 알려주면 좋겠어!\n"
     ]
    }
   ],
   "source": [
    "query = \"내 이름이 뭐지?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='안녕.', additional_kwargs={}, response_metadata={}, id='31ec90de-4637-4c50-89d0-d649780f8d15'), AIMessage(content='안녕! 어떻게 지내? 뭐 도와줄 일이 있어?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 34, 'total_tokens': 49, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-a8090f11-462e-49a1-95b8-cd4fc8456c23-0', usage_metadata={'input_tokens': 34, 'output_tokens': 15, 'total_tokens': 49, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='내 이름이 뭐지?', additional_kwargs={}, response_metadata={}, id='2b0eef9d-4bf2-4d83-a8d6-03912e92499f'), AIMessage(content='아쉽게도 너의 이름을 모르겠어. 너의 이름이 뭐야? 알려주면 좋겠어!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 62, 'total_tokens': 89, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-aea2d837-c345-4e43-af79-f33040e46727-0', usage_metadata={'input_tokens': 62, 'output_tokens': 27, 'total_tokens': 89, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}, next=(), config={'configurable': {'thread_id': 'abc345', 'checkpoint_ns': '', 'checkpoint_id': '1eff7b2d-c169-6c7f-8004-f98687af1ade'}}, metadata={'source': 'loop', 'writes': {'model': {'messages': AIMessage(content='아쉽게도 너의 이름을 모르겠어. 너의 이름이 뭐야? 알려주면 좋겠어!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 62, 'total_tokens': 89, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-aea2d837-c345-4e43-af79-f33040e46727-0', usage_metadata={'input_tokens': 62, 'output_tokens': 27, 'total_tokens': 89, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}}, 'thread_id': 'abc345', 'step': 4, 'parents': {}}, created_at='2025-03-02T22:08:24.048345+00:00', parent_config={'configurable': {'thread_id': 'abc345', 'checkpoint_ns': '', 'checkpoint_id': '1eff7b2d-b97e-6dfd-8003-79c1cd2b4dfa'}}, tasks=())"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 현재 status의 상태\n",
    "app.get_state(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KsQjKmlkawNv"
   },
   "source": [
    "내부에서 무슨 일이 일어나고 있는지 이해하는 데 도움이 되도록 [LangSmith 추적](https://smith.langchain.com/o/351c6cd9-1396-5c74-9478-1ee6a22a6433/projects/p/acec9d4d-4978-4597-adff-789cd42e200f?timeModel=%7B%22duration%22%3A%227d%22%7D)을 확인하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YPtfr1DrawNz"
   },
   "source": [
    "## **스트리밍 (Streaming)**  \n",
    "\n",
    "이제 우리는 작동하는 챗봇을 만들었습니다. 그러나 챗봇 애플리케이션의 사용자 경험(UX)에서 **매우 중요한 요소** 중 하나는 **스트리밍(Streaming)** 입니다.  \n",
    "\n",
    "LLM은 때때로 응답을 생성하는 데 시간이 걸릴 수 있습니다. 따라서 사용자 경험을 개선하기 위해 대부분의 애플리케이션은 **생성되는 각 토큰을 실시간으로 스트리밍**하여 사용자에게 보여줍니다. 이렇게 하면 사용자는 응답의 진행 상황을 실시간으로 확인할 수 있습니다.  \n",
    "\n",
    "사실, 이 작업은 매우 간단합니다!  \n",
    "\n",
    "기본적으로 LangGraph 애플리케이션에서 `.stream`은 애플리케이션 단계(예: 모델 응답 단계)를 스트리밍합니다. 그러나 `stream_mode=\"messages\"`를 설정하면 **출력 토큰을 실시간으로 스트리밍**할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wpy_OET1awN0",
    "outputId": "21345a84-6d23-426f-ce1a-04c2052024bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|안|녕하세요|,| 토|드|!| 농|담| 하나| 해|볼|게|요|:\n",
      "\n",
      "전|거|는| 넘어|지|지| 않|게| 될|까요|?\n",
      "\n",
      "|왜|냐|하면| 두| 바|퀴|가| 있기| 때문|이|죠|!| 😄|\n",
      "\n",
      "해|줘|요|!||나요|?| 더| 듣|고| 싶|으면| 언제|든|지| 말|"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# 스트리밍 설정을 위한 구성(config) 정의\n",
    "config = {\"configurable\": {\"thread_id\": \"abc789\"}}\n",
    "\n",
    "# 사용자 입력 메시지 및 언어 설정\n",
    "query = \"안녕하세요, 제 이름은 토드입니다. 농담 하나 해주세요.\"  # 사용자 입력 메시지\n",
    "language = \"한국어\"  # 대화 언어 설정\n",
    "\n",
    "# 입력 메시지를 HumanMessage 객체로 변환\n",
    "input_messages = [HumanMessage(query)]\n",
    "\n",
    "# LangChain 애플리케이션 스트리밍 시작\n",
    "for chunk, metadata in app.stream(\n",
    "    {\"messages\": input_messages, \"language\": language},  # 입력 메시지와 언어를 전달\n",
    "    config,  # 구성 정보 전달\n",
    "    stream_mode=\"messages\",  # 메시지 단위로 토큰을 스트리밍\n",
    "):\n",
    "    # AIMessage 객체만 필터링하여 출력\n",
    "    if isinstance(chunk, AIMessage):\n",
    "        print(chunk.content, end=\"|\")  # AI 응답 메시지를 실시간으로 출력 (구분자는 '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L6ccbk4nrJnU"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
