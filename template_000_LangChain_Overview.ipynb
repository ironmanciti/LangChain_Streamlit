{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc982432",
   "metadata": {
    "id": "2TypDOiTPbjE"
   },
   "source": [
    "# LangChain 기능 소개\n",
    "\n",
    "- 1. 프롬프트 템플릿과 로더를 사용하여 체인 구성  \n",
    "- 2. Runnable과 LangChain 표현 언어  \n",
    "- 3. RAG 체인 구축  \n",
    "- 4. 체인이 달린 도구 사용  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd28865",
   "metadata": {
    "id": "TOUiSLMxPzZY"
   },
   "source": [
    "## LangChain 개요\n",
    "\n",
    "LangChain으로 개발된 애플리케이션은 일반적으로 세 가지 범주로 나뉩니다.\n",
    "\n",
    "- 챗봇 : LLM을 이용하여 보다 지능적인 마케팅, 고객 지원, 교육 상호작용 구현.\n",
    "- 검색 증강 생성(RAG) Q&A : 대용량 문서 요약, 데이터 분석, 외부 소스를 참조하여 코드 생성에 사용.\n",
    "- 에이전트 시스템은 다중 에이전트 설정과 인간 상호작용을 포함하며 복잡한 워크플로우를 위해 LangGraph를 활용. 공급망 관리 및 운영 최적화와 같은 분야에 적용 가능.\n",
    "\n",
    "LangChain은 자연어를 실행 가능한 프로그램으로 변환하는 파이프라인을 생성할 수 있게 합니다. 이러한 체인을 활용함으로써 사용자는 자연어를 입력하고 보고서, 분석 또는 컴퓨터 프로그램과 같은 출력을 받을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4058cc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U langchain-core\n",
    "# !pip install -U langchain-openai\n",
    "# !pip install -U langchain-community\n",
    "# !pip install -U langchain-experimental\n",
    "# !pip install -U langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911800ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env 파일에서 API 키를 로드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0692a78",
   "metadata": {},
   "source": [
    "### 사용 가능한 LLM 목록 조회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869819bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용 가능한 모델 목록을 가져옵니다.\n",
    "# 각 모델의 ID 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb89ab0",
   "metadata": {
    "id": "XEi1gjmpW8ab"
   },
   "source": [
    "## LLM 연결\n",
    "\n",
    "OpenAI 및 Anthropic API에 연결합니다. 원하는 모델을 지정하여 ChatOpenAI 및 ChatAnthropic 클래스의 인스턴스를 만듭니다. llm_claude3 인스턴스를 사용하여 간단한 쿼리를 호출하여 설정을 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63eb8f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_anthropic import ChatAnthropic\n",
    "# llm = ChatAnthropic(model=\"claude-3-5-haiku-20241022\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4c52c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c570150",
   "metadata": {},
   "source": [
    "### Messages\n",
    "- AIMessage: AI(인공지능) 모델이 생성한 메시지를 나타냅니다.  \n",
    "예를 들어, AI 모델이 사용자의 질문에 대해 응답을 생성할 때 이 클래스가 사용됩니다.\n",
    "\n",
    "- HumanMessage: 사람(사용자)이 생성한 메시지를 나타냅니다.  \n",
    "사용자가 입력한 텍스트나 질문 등이 여기에 해당됩니다.\n",
    "\n",
    "- StemMessage: AI 행동을 프라이밍하기 위한 메시지.\n",
    "시스템 메시지는 일반적으로 일련의 입력 메시지 중 첫 번째로 전달됩니다. 일반적으로 대화의 흐름을 제어하거나 특정 지침을 제공하기 위해 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562cb92b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c825fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system과 human/user 메시지를 이용한 기본 요청"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c11466",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fddef5a6",
   "metadata": {},
   "source": [
    "### 수학 선생님"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26177d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd01cbbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1adac47",
   "metadata": {
    "id": "2fi6_NvW3MaE"
   },
   "source": [
    "##  1. 프롬프트 템플릿과 로더를 사용하여 체인 구성  \n",
    "\n",
    "- LLM에서의 Chain 은 Data Processing 에서의 Pipeline 과 유사한 개념"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cf38fd",
   "metadata": {
    "id": "G447ezl5X5ye"
   },
   "source": [
    "### 체인의 구성 요소 - Runnables\n",
    "- 프롬프트 : LLM의 응답을 안내하는 템플릿  \n",
    "- LLM 또는 채팅 모델 : 프롬프트에 따라 응답을 생성하는 엔진  \n",
    "- 출력 파서 : LLM의 출력을 파싱하는 도구  \n",
    "- 도구 : LLM이 API에서 추가 정보를 추출하거나 코드를 실행하여 LLM을 에이전트로 전환할 수 있게 해주는 확장 기능  \n",
    "- 일반 함수 : 서로 연결될 수 있는 추가적인 일반 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6234c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple prompt template 생성\n",
    "# {topic} 변수에서 사용자의 query 가 대체된다.\n",
    "# prompt template 을 이용하여 prompt 생성 - old style\n",
    "# prompt template 을 이용하여 prompt 생성 - new style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f89b565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe operator \"|\"\" 를 이용하여 하나 이상의 chain 을 결합"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e18f6f4",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0b5fbe",
   "metadata": {},
   "source": [
    "## 2. Runnable과 LangChain 표현 언어  \n",
    "\n",
    "- LCEL(LangChain Expression Language) 는 Runnables 를 chain 으로 구성하는 방법\n",
    "\n",
    "LCEL은 기본 구성 요소에서 복잡한 체인을 구축하는 것을 간소화합니다. 파이프 연산자(|)를 사용하여 다양한 구성 요소를 체인으로 연결하고 한 요소에서 다음 요소로 출력을 공급합니다. 이런 방식으로 구성된 체인의 간단한 예로는 모델과 출력 파서가 결합된 프롬프트가 있습니다.  이러한 구성 요소들을 runnables 라고 부릅니다.  \n",
    "\n",
    "`chain=prompt | model | output_parser`\n",
    "\n",
    "- Chain 구성  \n",
    "    - 체인에 대한 입력(일반적으로 사전)\n",
    "    - 입력은 프롬프트로 전송됩니다.\n",
    "    - 프롬프트 값은 LLM 또는 채팅 모델로 전송됩니다.\n",
    "    - Chatmodel이 채팅 메시지를 반환합니다.\n",
    "    - 파서는 채팅 메시지에서 문자열을 추출합니다.\n",
    "    - 문자열은 체인의 출력입니다\n",
    "\n",
    "- LangChain의 runnable 객체들:\n",
    "\n",
    "    - RunnableSequence : 여러 runnable 구성 요소를 연결하여 각 구성 요소가 입력을 처리하고 출력을 다음 구성 요소에 전달\n",
    "    - RunnableLambda : Python의 호출 가능한 요소(함수 등)를 실행 가능한 구성 요소로 바꿔서 체인으로 통합\n",
    "    - RunnablePassthrough : 입력을 변경하지 않고 통과시키거나 출력에 추가 키를 추가. placeholder 역할을 하거나 시퀀스에 유연하게 통합할 수 있다.\n",
    "    - RunnableParallel : 여러 개의 실행 파일을 동시에 실행하여 두 개의 체인이 동일한 입력에서 실행되지만 다른 출력을 반환하는 분기를 허용."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b14731",
   "metadata": {},
   "source": [
    "### Runnables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e39d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df31066c",
   "metadata": {
    "id": "InN3aD1qGwmD"
   },
   "source": [
    "###  \"|\" 연산자를 이용하여 Runnable Sequence chain 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc7d689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84e03f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66c41ee6",
   "metadata": {
    "id": "j_VLKGZ1HO7d"
   },
   "source": [
    "### RunnableLambda 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7510cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RunnableLambda를 사용하여 Python 함수를 체인에 삽입합니다.\n",
    "# 사용자 정의 람다 함수를 정의하고 이를 RunnableLambda에 래핑합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcec659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bb6b48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7aea959c",
   "metadata": {},
   "source": [
    "## 3. 체인이 달린 도구 사용  \n",
    "\n",
    "- 도구는 에이전트, 체인 또는 대형 언어 모델(LLM)이 세상과 상호 작용할 수 있게 하는 인터페이스입니다.\n",
    "    - Python REPL, Wikipdedia, YouTube, Zapier, Gradio, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e64fd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade -q youtube_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b77268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유튜브를 검색하는 함수\n",
    "# YouTubeSearchTool 인스턴스 생성\n",
    "# 아무 키워드로 유튜브 검색 실행 --> 함수가 잘 실행되는 것 확인."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55352509",
   "metadata": {},
   "source": [
    "- YouTubeSearchTool 함수를 LLM 에 넘겨 주고 LLM이 이 함수를 이용하여 세상과 상호 작용 (유튜브 검색)할 수 있도록 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83101727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1단계: LLM이 어떤 tool과 args를 쓸지 판단할 수 있도록 함\n",
    "# YouTube 도구를 LLM에 바인딩 --> OpenAI API 의 'tools=' parameter에 함수명과 \n",
    "# 함수 호출에 필요한 parameter 정보 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913fd477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# msg에서 OpenAI LLM이 구성해준 함수호출 parameter 발췌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5596c3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YouTubeSearchTool 호출에 필요한 parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4cfedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2단계: Tool call → 파라미터 추출 → Tool 실행\n",
    "# llm_with_tools에서 추출된 인수로 YouTubeSearchTool을 사용하여 유튜브 검색 실행하는 chain 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4277e5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f6c29b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb860956",
   "metadata": {},
   "source": [
    "### Chains 종류\n",
    "\n",
    "**LangChain**을 사용하여 다양한 체인(Chain) 및 LLM(대규모 언어 모델) 기반 애플리케이션을 구축합니다.\n",
    "\n",
    "**1. Simple Chain (단일 체인)**  \n",
    "- 하나의 프롬프트를 통해 LLM(OpenAI)을 사용하여 텍스트를 생성합니다.  \n",
    "\n",
    "\n",
    "**2. Simple Sequential Chain (연속 체인)**  \n",
    "-  여러 LLM 호출을 연속적으로 수행하여 출력을 다음 입력으로 전달합니다.  \n",
    "\n",
    "**3. Document 요약 체인**  \n",
    "- **목적:** 텍스트 문서를 요약합니다.  \n",
    "\n",
    "**4. 텍스트를 Vector Store로 변환**  \n",
    "- **4.1 VectortstoreIndexCreator**   \n",
    "- **4.2 Chroma DB 사용**  \n",
    "\n",
    "**5. HTTP Request Chain (웹 요청 체인)**  \n",
    "- HTTP 요청을 통해 외부 웹 데이터에서 정보를 추출합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621933b3",
   "metadata": {},
   "source": [
    "### 1. Simple Chain (단일 체인)\n",
    "- 가장 기본적인 유형의 체인\n",
    "- 입력 프롬프트를 수신하고 이를 사용하여 텍스트를 생성하는 역할을 담당하는 언어 모델(LLM) 하나만 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aadc406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain = prompt.pipe(llm)\n",
    "# 입력 변수만 지정하여 체인을 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1e4b79",
   "metadata": {},
   "source": [
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0bfb1b",
   "metadata": {},
   "source": [
    "### 2. Simple Sequential Chains (연속 체인)\n",
    "- Sequential Chain은 언어 모델에 대한 일련의 연속 호출 포함\n",
    "- 이 접근 방식은 한 호출에서 생성된 출력을 다른 호출의 입력으로 활용할 때 특히 유용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b860d60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ccceb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077a1cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
