{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d51f4020-8cb4-4561-b6d2-98589737dda8",
   "metadata": {},
   "source": [
    "# LangGraph를 사용한 고객 지원 챗봇을 구축\n",
    "\n",
    "- 웹 검색을 통해 일반적인 질문에 답변 \n",
    "- 대화 상태를 유지하여 연속적인 대화  \n",
    "- 복잡한 질문을 사람이 검토하도록 라우팅  \n",
    "- 사용자 지정 상태(Custom State)를 활용하여 챗봇의 동작 제어  \n",
    "- 대화 흐름을 되돌리고(Rewind), 다른 대화 경로 탐색 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a213aa99-6fe2-465e-a21b-b743cabfb74e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb0aec0a-9a1e-45a3-bf66-d89895d172f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangSmith 추적 설정 활성화\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fec86f20-d4b0-4cfa-99a9-0c5a281f40f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df89407-dce9-4ce5-bca0-4e3b04cd17cd",
   "metadata": {},
   "source": [
    "먼저 모델을 직접 사용해 봅니다. `ChatModel`은 LangChain의 **\"Runnable\"** 인스턴스이며, 이는 표준화된 인터페이스를 통해 상호작용할 수 있음을 의미합니다.  \n",
    "\n",
    "모델을 간단하게 호출하려면 `.invoke` 메서드에 **메시지 목록**을 전달하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb8a90fd-c857-4763-b7a8-c14e5b710092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요, 길동님! 반가워요. 어떻게 도와드릴까요?'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "response = llm.invoke([HumanMessage(content=\"안녕! 나는 길동이야.\")])\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71051507-d55c-4af8-b843-f6708ef3c6f5",
   "metadata": {},
   "source": [
    "모델 자체는 **상태(state)** 라는 개념을 가지고 있지 않습니다. 예를 들어, 후속 질문을 하면:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c75c18fa-413d-483c-be3c-219c7848c3d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'죄송하지만, 당신의 이름을 알 수 없습니다. 대화 중에 언급된 적이 없기 때문입니다. 당신의 이름을 알려주시면 좋겠습니다!'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = llm.invoke([HumanMessage(content=\"내 이름이 뭐라고 했지?\")])\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "26f2aba7-ac8f-4da5-b142-9318db879d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'당신의 이름은 길동입니다. 다른 질문이나 궁금한 점이 있으면 말씀해 주세요!'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "response = llm.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"안녕! 나는 길동이야.\"),\n",
    "        AIMessage(content=\"안녕하세요, 길동님. 무엇을 도와 드릴까요?\"),\n",
    "        HumanMessage(content=\"내 이름이 뭐라고 했지?\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b06d60-c560-4b1d-9202-05f16b3cac0d",
   "metadata": {},
   "source": [
    "<br>\n",
    "이제 좋은 응답을 받는 것을 확인할 수 있습니다!  \n",
    "\n",
    "이것이 챗봇이 **대화형 상호작용**을 할 수 있는 기본 아이디어입니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75320d9a-081a-4388-9765-dfaae27014c6",
   "metadata": {},
   "source": [
    "### **Part 1: 기본 챗봇 만들기¶**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c7e75eb3-a653-429d-91a6-6091c9e5f319",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# MessageState를 기반으로 그래프를 구성하기 위한 graph_builder 설정\n",
    "graph_builder = StateGraph(state_schema=MessagesState)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408b2346-56b6-48f1-9bbf-aedb2a115063",
   "metadata": {},
   "source": [
    "다음으로 **\"chatbot\" 노드**를 추가합니다.  \n",
    "**노드(Nodes)** 는 작업의 단위를 나타내며, 일반적으로 **일반적인 Python 함수**로 구성됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cb6e4cae-4c81-47c3-a856-ded4e1af8191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x163cf68ebb0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 챗봇 함수 정의\n",
    "def chatbot(state: MessagesState):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "# 첫 번째 인자는 노드의 고유한 이름 (\"chatbot\")\n",
    "# 두 번째 인자는 노드가 실행될 때 호출될 함수 또는 객체\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b93f8e-d18c-403c-af6b-610278e3eecf",
   "metadata": {},
   "source": [
    "- 챗봇 노드 함수는 **현재 상태(State)를 입력**으로 받고, **업데이트된 메시지 리스트**를 `\"messages\"` 키에 담아 **딕셔너리 형태로 반환**합니다.  \n",
    "- 이 패턴은 **모든 LangGraph 노드 함수의 기본 구조**입니다.  \n",
    "\n",
    "**다음 단계:**  \n",
    "- **엔트리 포인트(Entry Point)** 를 추가  \n",
    "- **엔트리 포인트**는 **그래프 실행 시 시작 지점을 정의**하며, **매번 그래프를 실행할 때 어디서부터 작업을 시작할지 지정하는 역할**을 합니다.\n",
    "- 마찬가지로, **종료 지점(Finish Point)** 을 설정합니다. 이는 그래프에게 **\"이 노드가 실행될 때마다, 여기서 작업을 종료할 수 있다.\"** 라고 지시하는 역할을 합니다.\n",
    "- 마지막으로, 그래프를 실행할 수 있도록 설정해야 합니다. 이를 위해 **`compile()`** 메서드를 그래프 빌더에서 호출합니다.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "29fb9bdc-0179-4417-ab7c-f27d93036007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x00000163CF68E340>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "graph = graph_builder.compile()\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "29921703-013a-402a-9e0d-5d4bccfee536",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'dispalay' from 'IPython.display' (C:\\Users\\trimu\\anaconda3\\envs\\langchain\\lib\\site-packages\\IPython\\display.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image, dispalay\n\u001b[0;32m      3\u001b[0m display(Image(graph\u001b[38;5;241m.\u001b[39mget_graph()\u001b[38;5;241m.\u001b[39mdraw_mermaid_png()))\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'dispalay' from 'IPython.display' (C:\\Users\\trimu\\anaconda3\\envs\\langchain\\lib\\site-packages\\IPython\\display.py)"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image, dispalay\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355f82c2-10cd-45b8-ab94-6742a795b748",
   "metadata": {},
   "source": [
    "### **챗봇 실행**  \n",
    "\n",
    "대화 루프에서 언제든지 **\"quit\"**, **\"exit\"**, 또는 **\"q\"** 를 입력하면 종료할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0ce987f1-05ab-42e3-8c9f-96eb0395aa5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "사용자:  안녕 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: 안녕하세요! 어떻게 도와드릴까요?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "사용자:  q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "종료합니다.\n"
     ]
    }
   ],
   "source": [
    "def stream_graph_updates(user_input: str):\n",
    "    \"\"\"\n",
    "    그래프를 스트리밍 방식으로 업데이트하는 함수\n",
    "    사용자 입력을 받아, LLM이 응답하는 과정을 streaming 방식으로 출력\n",
    "    \"\"\"\n",
    "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):  \n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)  # 최신 응답 메시지를 출력\n",
    "\n",
    "\n",
    "# 무한 루프 (사용자가 \"quit\", \"exit\", \"q\"를 입력하면 종료)\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"사용자: \")  \n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]: \n",
    "            print(\"종료합니다.\") \n",
    "            break\n",
    "\n",
    "        stream_graph_updates(user_input) \n",
    "    except:\n",
    "        # `input()`이 사용 불가능한 경우 예외 처리 (예: 특정 환경에서 실행 시)\n",
    "        user_input = \"LangGraph 에 대해 말해줘.\"  \n",
    "        print(\"사용자: \" + user_input)\n",
    "        stream_graph_updates(user_input)  \n",
    "        break  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649d8085-2d02-4eb0-86c9-560acd5fd295",
   "metadata": {},
   "source": [
    "LangGraph를 사용하여 첫 번째 챗봇을 구축 했습니다.  \n",
    "\n",
    "다음 단계에서는 웹 검색 도구를 추가하여 챗봇의 지식을 확장하고, 더 강력한 기능을 갖추도록 만들겠습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6448ed23-0ce7-4431-a4a2-793a0916d3de",
   "metadata": {},
   "source": [
    "## **Part 2: 도구를 활용한 챗봇 강화**   \n",
    "이제 챗봇이 **웹에서 관련 정보를 찾아 더 나은 답변을 제공할 수 있도록 개선**합니다. \n",
    "\n",
    "---\n",
    "먼저 **Tavily 검색 엔진**을 사용하기 위해 필요한 패키지를 설치하고 **`TAVILY_API_KEY`** 를 설정 합니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7a4b30-dbfe-4a97-930e-dd021949c6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture --no-stderr\n",
    "# %pip install -U tavily-python langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7653298e-26bc-4552-af74-ad5fd2e9d8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "tool.invoke(\"LangGraph에서 node가 뭐야?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6355a382-c539-4458-bd08-18826d82aea2",
   "metadata": {},
   "source": [
    "결과는 **페이지 요약(Summaries)** 으로, **챗봇이 질문에 답변할 때 사용할 수 있습니다.**  \n",
    "\n",
    "다음 코드는 **Part 1과 동일하지만, 한 가지 차이가 있습니다.**  \n",
    "\n",
    "**LLM에 `bind_tools`를 추가하여, LLM이 검색 엔진을 사용할 때 올바른 JSON 형식을 인식하도록 설정했습니다.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92310279-6111-452c-a7eb-80cf28f755fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(MessagesState)\n",
    "\n",
    "# 수정 사항: LLM이 사용할 수 있는 도구(Tools)를 명시적으로 설정\n",
    "llm_with_tools = llm.bind_tools(tools) \n",
    "\n",
    "# 챗봇 함수 정의\n",
    "def chatbot(state: MessagesState):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}  \n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a50b3b7-c7d3-4340-9c75-96f6d47b158d",
   "metadata": {},
   "source": [
    "이제 도구가 호출되었을 때 실제로 실행하는 함수를 만들어야 합니다. 이를 위해 새로운 노드(node)를 추가하여 도구를 실행할 수 있도록 설정합니다.\n",
    "\n",
    "이 노드는 Anthropic, OpenAI, Google Gemini 등 여러 LLM 제공업체에서 지원하는 **`tool_calling` 기능**을 활용합니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7f8142-76e1-4f1d-b59a-6a460decc8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "# \"tools\" 노드 생성 및 그래프에 추가\n",
    "tool_node = ToolNode(tools=[tool])  \n",
    "graph_builder.add_node(\"tools\", tool_node)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c061dc-e417-4661-9eef-ea607877126d",
   "metadata": {},
   "source": [
    "**조건부 엣지(Conditional Edges)의 동작 방식**  \n",
    "\n",
    "- 조건부 엣지는 특정 노드에서 시작됩니다. 즉, 'chatbot' 노드가 실행될 때마다, 다음과 같은 경로를 결정합니다.\n",
    "\n",
    "1️) 만약 챗봇이 도구(`tool_calls`)를 호출하면 'tools' 노드로 이동   \n",
    "2️) 만약 챗봇이 직접 응답하면 `END`로 이동하여 실행 종료\n",
    "\n",
    "\n",
    "**`tools_condition`**  \n",
    "\n",
    "- **`tool_calls`가 없는 경우 `END` 문자열을 반환하여 실행을 종료** 합니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f1eb6c-285b-4deb-bdb4-587b4062a673",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",  \n",
    "    tools_condition,\n",
    ")\n",
    "\n",
    "# 도구 사용이 완료되면 다시 챗봇 노드로 돌아가서 다음 단계 결정\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "# 그래프의 시작점 정의 (START → chatbot)\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "# 그래프 컴파일 (최종 그래프 생성)\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd3827d-f5e4-49d7-a436-93e231b04ce0",
   "metadata": {},
   "source": [
    "이제 챗봇에게 **훈련 데이터에 없는 질문도 할 수 있습니다.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27cb4c5-0f14-403d-ada3-4eb44500eb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"사용자: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"종료합니다.\")\n",
    "            break\n",
    "\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        user_input = \"LangGraph에 대해 알고 있는 것을 말해줘.\"\n",
    "        print(\"사용자: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0401e8-6b7b-4320-b8e6-13c17a99de08",
   "metadata": {},
   "source": [
    "이제 LangGraph에서 검색 엔진을 활용할 수 있는 대화형 에이전트(Conversational Agent)를 만들었습니다\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c7a1b5-6039-4915-9b70-61b4d825737f",
   "metadata": {},
   "source": [
    "## **Part 3: 챗봇에 메모리 기능 추가¶**  \n",
    "\n",
    "현재 챗봇은 **사용자 질문에 도구를 활용해 답변할 수 있지만, 이전 대화의 맥락을 기억하지 못합니다.**  \n",
    "이 때문에 **일관된 멀티턴(Multi-turn) 대화를 진행하는 데 한계가 있습니다.**  \n",
    "\n",
    "LangGraph는 **\"지속적 체크포인트(Persistent Checkpointing)\"** 기능을 통해 이 문제를 해결합니다.  \n",
    "\n",
    "그래프를 컴파일할 때 checkpointing을 활성화하고 그래프를 호출할 때 `thread_id`를 제공하면, LangGraph가 자동으로 상태(state)를 저장하고, 다음 실행 시 이전 상태를 복원합니다.  \n",
    "\n",
    "즉, **동일한 `thread_id`** 를 사용하여 그래프를 호출하면, 이전 대화 상태를 불러와서 이어서 대화할 수 있습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf74912-e1bd-4753-96f0-ad3398a9590a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1e5e51-8ec4-4b53-9154-c83b0097756a",
   "metadata": {},
   "source": [
    "우리는 현재 **메모리를 활용하는(in-memory) 체크포인터**를 사용하고 있습니다.  \n",
    "\n",
    "이 방식은 튜토리얼 환경에서는 편리하지만, 데이터가 메모리에만 저장되므로 영구적이지 않습니다. 실제 프로덕션 환경에서는 `SqliteSaver` 또는 `PostgresSaver`를 사용하여 데이터베이스(DB)와 연결하는 것이 일반적입니다.\n",
    "\n",
    "---\n",
    "\n",
    "## **그래프 정의**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551535ee-c7e8-4ff6-9cfa-b310a9c65334",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "graph_builder = StateGraph(MessagesState)\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def chatbot(state: MessagesState):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "# # 도구가 호출될 때마다, 다음 단계를 결정하기 위해 챗봇으로 돌아갑니다.\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "# 제공된 체크포인터와 함께 그래프를 컴파일\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98064cc1-ccc0-4221-9a75-9612f109c1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38c5908-301c-4570-a39e-3890e00d3249",
   "metadata": {},
   "source": [
    "이제 챗봇과 상호작용할 수 있습니다. 먼저, 이 대화를 식별할 수 있는 **`thread`(스레드)** 를 선택합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de68f3f7-6674-4331-9306-e5c6f05fbda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "user_input = \"안녕하세요! 제 이름은 길동이에요.\"\n",
    "\n",
    "# config는 stream() 또는 invoke()의 두 번째 인자\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79049d77-3779-4e35-90d7-897703930630",
   "metadata": {},
   "source": [
    "이제 후속 질문(follow-up question)을 해봅시다. 챗봇이 사용자의 이름을 기억하는지 확인해 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c550ffba-4df9-479c-a130-2338f7132ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"내 이름이 뭐야?\"\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd651247-ce10-4cae-b1ea-6d3a283ae48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `thread_id`를 \"1\" 대신 \"2\"로 변경합니다.\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    {\"configurable\": {\"thread_id\": \"2\"}},\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fbbc5a-8a63-461d-a46c-224813666389",
   "metadata": {},
   "source": [
    "---\n",
    "지금까지 두 개의 서로 다른 thread에서 여러 개의 체크포인트를 생성했습니다. 체크포인트에는 어떤 정보가 저장되는 정보는 다음과 같습니다. \n",
    "\n",
    "- 현재 상태 값(Current State Values) \n",
    "- 해당 상태와 연결된 `config` 정보  \n",
    "- 다음으로 처리할 노드(Next Node to Process) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db83c64-770e-4793-9088-b7b04ade4f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589b0b60-b7ba-4cbe-a33f-f451e729fb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 상태 값\n",
    "snapshot.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8854f3b-fc78-45a5-87ef-7c7c8ca696c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해당 상태와 관련된 config 정보\n",
    "snapshot.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5572c918-8eca-4cf7-9da4-d0624d2a057e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음으로 처리할 node\n",
    "snapshot.next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c294f10-0aaf-4feb-8642-562f9f22ba90",
   "metadata": {},
   "source": [
    "### 프롬프트 템플릿(Prompt Templates)을 사용하여 LLM 호출 최적화\n",
    "\n",
    "**프롬프트 템플릿** 은 **원시 사용자 입력(raw user input)** 을 LLM이 처리할 수 있는 형식으로 변환하는 데 도움을 줍니다.   \n",
    "\n",
    "1. 먼저, **시스템 메시지(system message)** 를 추가하여 **사용자 정의 지침(custom instructions)** 을 포함시킵니다. (여전히 메시지를 입력으로 사용)  \n",
    "2. 다음으로, 메시지 외에 **더 많은 입력 정보** 를 추가합니다.  \n",
    "\n",
    "#### **시스템 메시지(System Message) 추가하기**\n",
    "\n",
    "시스템 메시지를 추가하기 위해 **`ChatPromptTemplate`** 을 생성합니다. 여기서는 메시지 전달을 위해 **`MessagesPlaceholder`** 를 사용하겠습니다.  \n",
    "\n",
    "이렇게 하면 LLM에 전달되는 입력이 더 구조화되고, 챗봇의 동작을 더 정교하게 제어할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a0b996-03aa-43fe-87e8-497ffa7f4c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# LLM이 사용자 입력을 더 잘 처리할 수 있도록 프롬프트 템플릿을 설정합니다.\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        # LLM의 동작 방식을 정의하는 지침\n",
    "        (\n",
    "            \"system\",\n",
    "            \"당신은 친구 처럼 말합니다. 모든 질문에 최선을 다해 대답하세요.\",\n",
    "        ),\n",
    "\n",
    "        # Messages Placeholder - 이전 대화 메시지들을 전달합\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c33e0d-797c-4456-8c02-4d61579dd66a",
   "metadata": {},
   "source": [
    "이제 이 템플릿을 통합하여 애플리케이션을 업데이트할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c490a87c-0ab3-4c3e-8d77-5bbe38a48e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "# 모델 호출 함수 정의\n",
    "def chatbot(state: MessagesState):\n",
    "    prompt = prompt_template.invoke(state)   # 현재 상태(state)를 기반으로 프롬프트를 생성\n",
    "    response = llm.invoke(prompt)        # 생성된 프롬프트를 LLM에 전달하여 응답 생성\n",
    "    return {\"messages\": response}   # 모델의 응답을 딕셔너리 형태로 반환\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "# START에서 \"chatbot\" 노드로 이동하도록 엣지 정의\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "# 그래프를 메모리 체크포인트와 함께 컴파일합니다.\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd72123-4664-46b0-b462-ba21ae0e7753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'configurable' 키를 사용하여 추가적인 설정 값을 전달합니다.\n",
    "# 여기서는 'thread_id'를 사용하여 특정 대화 스레드를 식별합니다.\n",
    "config = {\"configurable\": {\"thread_id\": \"abc345\"}}\n",
    "\n",
    "# 메시지 목록에 사용자 메시지 추가\n",
    "input_messages = [HumanMessage(\"안녕.\")]\n",
    "\n",
    "# 애플리케이션 호출\n",
    "# 메시지 상태(State), 설정(config) 전달\n",
    "output = graph.invoke({\"messages\": input_messages}, config)\n",
    "\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd43b67-d597-4fe8-bd4b-94c3ea80659a",
   "metadata": {},
   "source": [
    "## **Part 4: 인간 개입**\n",
    "\n",
    "작업을 성공적으로 수행하려면 **사람의 입력(human input)** 이 필요할 수도 있습니다.  \n",
    "또한, 특정 작업을 실행하기 전에 **사람의 승인(human approval)** 을 요구하여 올바르게 동작하는지 확인하고 싶을 수도 있습니다.  \n",
    "\n",
    "---\n",
    "\n",
    "## **LangGraph의 Human-in-the-loop 지원**  \n",
    "LangGraph의 **영속성 계층(persistence layer)** 은 **\"Human-in-the-loop\" 워크플로우** 를 지원합니다.  \n",
    "이를 통해 **실행을 일시 중지(pause)하고, 사용자 피드백을 기반으로 다시 실행(resume)** 할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc41ab7-6d2c-45f0-9ac9-3da7c3028b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "@tool\n",
    "def human_assistance(query: str) -> str:\n",
    "    \"\"\"Request assistance from a human.\"\"\"\n",
    "    human_response = interrupt({\"query\": query})\n",
    "    return human_response[\"data\"]\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool, human_assistance]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    message = llm_with_tools.invoke(state[\"messages\"])\n",
    "    # 도구 실행 중에 중단이 발생하므로\n",
    "    # 재개할 때 도구 호출이 반복되지 않도록 병렬 도구 호출을 비활성화합니다.\n",
    "    assert len(message.tool_calls) <= 1\n",
    "    return {\"messages\": [message]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0733a4e-9031-421a-b593-715580204003",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = MemorySaver()\n",
    "\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f20ebd-d559-465d-9f79-522979d13afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c066770e-d079-47fc-aaf4-2739c94942f5",
   "metadata": {},
   "source": [
    "이제 새로운 human_assistance 도구를 사용할 수 있는 질문을 챗봇에 입력해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4f3d02-9cf2-4565-8d25-bf72bb8123d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"AI 에이전트를 만드는 데 전문가의 지침이 필요합니다. 도움을 요청해 주시겠습니까?\"\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3d3e97-d268-401f-89b1-77280c9908f8",
   "metadata": {},
   "source": [
    "--------------------\n",
    "챗봇이 도구 호출을 생성했지만 실행이 중단되었습니다! 그래프 상태를 검사하면 도구 노드에서 멈췄음을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b35e8ac-b910-4507-bd98-a0aae027cc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "snapshot.next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ced6c7-0a42-43e7-a005-519e1491f7a6",
   "metadata": {},
   "source": [
    "Python의 내장 input() 함수와 유사하게, 도구 내부에서 interrupt를 호출하면 실행이 일시 중지됩니다. \n",
    "\n",
    "실행을 재개하려면 도구에서 예상하는 데이터가 포함된 Command 객체를 전달합니다. 이 데이터의 형식은 필요에 따라 사용자 정의할 수 있습니다. 여기서는 \"data\" 키가 있는 dict만 있으면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c810ff7-e773-4925-82a5-f6b4fabf56a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command\n",
    "\n",
    "human_response = (\n",
    "    \"저희, 전문가들이 도와드리겠습니다! 에이전트를 빌드하려면 LangGraph를 확인해보시기를 권장합니다.\"\n",
    "    \"단순 자율 에이전트보다 훨씬 더 안정적이고 확장 가능합니다.\"\n",
    ")\n",
    "\n",
    "human_command = Command(resume={\"data\": human_response})\n",
    "\n",
    "events = graph.stream(human_command, config, stream_mode=\"values\")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e790582e-65c4-4381-85e1-138536b4c828",
   "metadata": {},
   "source": [
    "-----------------\n",
    "인터럽트를 사용하여 채팅봇에 인간 참여 루프 실행을 추가하여 필요할 때 인간의 감독과 개입을 허용했습니다. 이를 통해 AI 시스템으로 만들 수 있는 잠재적인 UI가 열립니다. 이미 체크포인터를 추가했으므로 기본 지속성 계층이 실행되는 한 그래프를 무기한 일시 중지하고 아무 일도 없었던 것처럼 언제든지 다시 시작할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e745c557-6881-4ea8-b557-05cd5104d7c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
