{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TypDOiTPbjE"
   },
   "source": [
    "# LangChain 기능 소개\n",
    "\n",
    "- 1. 프롬프트 템플릿과 로더를 사용하여 체인 구성  \n",
    "- 2. Runnable과 LangChain 표현 언어  \n",
    "- 3. RAG 체인 구축  \n",
    "- 4. 체인이 달린 도구 사용  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TOUiSLMxPzZY"
   },
   "source": [
    "## LangChain 개요\n",
    "\n",
    "LangChain으로 개발된 애플리케이션은 일반적으로 세 가지 범주로 나뉩니다.\n",
    "\n",
    "- 챗봇 : LLM을 이용하여 보다 지능적인 마케팅, 고객 지원, 교육 상호작용 구현.\n",
    "- 검색 증강 생성(RAG) Q&A : 대용량 문서 요약, 데이터 분석, 외부 소스를 참조하여 코드 생성에 사용.\n",
    "- 에이전트 시스템은 다중 에이전트 설정과 인간 상호작용을 포함하며 복잡한 워크플로우를 위해 LangGraph를 활용. 공급망 관리 및 운영 최적화와 같은 분야에 적용 가능.\n",
    "\n",
    "LangChain은 자연어를 실행 가능한 프로그램으로 변환하는 파이프라인을 생성할 수 있게 합니다. 이러한 체인을 활용함으로써 사용자는 자연어를 입력하고 보고서, 분석 또는 컴퓨터 프로그램과 같은 출력을 받을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U langchain-core\n",
    "# !pip install -U langchain-openai\n",
    "# !pip install -U langchain-community\n",
    "# !pip install -U langchain-experimental\n",
    "# !pip install -U langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FXRwb1YcsW1j",
    "outputId": "7e5cff59-b6f5-446d-e3cc-93891014f5c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# env 파일에서 API 키를 로드\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사용 가능한 LLM 목록 조회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gpt-4-0613', 'gpt-4', 'gpt-3.5-turbo', 'gpt-4o-audio-preview-2025-06-03', 'gpt-4.1-nano', 'gpt-image-1', 'codex-mini-latest', 'gpt-4o-realtime-preview-2025-06-03', 'davinci-002', 'babbage-002', 'gpt-3.5-turbo-instruct', 'gpt-3.5-turbo-instruct-0914', 'dall-e-3', 'dall-e-2', 'gpt-4-1106-preview', 'gpt-3.5-turbo-1106', 'tts-1-hd', 'tts-1-1106', 'tts-1-hd-1106', 'text-embedding-3-small', 'text-embedding-3-large', 'gpt-4-0125-preview', 'gpt-4-turbo-preview', 'gpt-3.5-turbo-0125', 'gpt-4-turbo', 'gpt-4-turbo-2024-04-09', 'gpt-4o', 'gpt-4o-2024-05-13', 'gpt-4o-mini-2024-07-18', 'gpt-4o-mini', 'gpt-4o-2024-08-06', 'chatgpt-4o-latest', 'o1-preview-2024-09-12', 'o1-preview', 'o1-mini-2024-09-12', 'o1-mini', 'gpt-4o-realtime-preview-2024-10-01', 'gpt-4o-audio-preview-2024-10-01', 'gpt-4o-audio-preview', 'gpt-4o-realtime-preview', 'omni-moderation-latest', 'omni-moderation-2024-09-26', 'gpt-4o-realtime-preview-2024-12-17', 'gpt-4o-audio-preview-2024-12-17', 'gpt-4o-mini-realtime-preview-2024-12-17', 'gpt-4o-mini-audio-preview-2024-12-17', 'o1-2024-12-17', 'o1', 'gpt-4o-mini-realtime-preview', 'gpt-4o-mini-audio-preview', 'computer-use-preview', 'o3-mini', 'o3-mini-2025-01-31', 'gpt-4o-2024-11-20', 'gpt-4.5-preview', 'gpt-4.5-preview-2025-02-27', 'computer-use-preview-2025-03-11', 'gpt-4o-search-preview-2025-03-11', 'gpt-4o-search-preview', 'gpt-4o-mini-search-preview-2025-03-11', 'gpt-4o-mini-search-preview', 'gpt-4o-transcribe', 'gpt-4o-mini-transcribe', 'o1-pro-2025-03-19', 'o1-pro', 'gpt-4o-mini-tts', 'o4-mini-2025-04-16', 'o4-mini', 'gpt-4.1-2025-04-14', 'gpt-4.1', 'gpt-4.1-mini-2025-04-14', 'gpt-4.1-mini', 'gpt-4.1-nano-2025-04-14', 'gpt-3.5-turbo-16k', 'tts-1', 'whisper-1', 'text-embedding-ada-002']\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# 사용 가능한 모델 목록을 가져옵니다.\n",
    "models = openai.models.list()\n",
    "\n",
    "# 각 모델의 ID 출력\n",
    "print([model.id for model in models])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XEi1gjmpW8ab"
   },
   "source": [
    "## LLM 연결\n",
    "\n",
    "OpenAI 및 Anthropic API에 연결합니다. 원하는 모델을 지정하여 ChatOpenAI 및 ChatAnthropic 클래스의 인스턴스를 만듭니다. llm_claude3 인스턴스를 사용하여 간단한 쿼리를 호출하여 설정을 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jSY2uUq8ssCp"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-nano\")\n",
    "\n",
    "# from langchain_anthropic import ChatAnthropic\n",
    "# llm = ChatAnthropic(model=\"claude-3-5-haiku-20241022\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "id": "NFWMvMRitGX-",
    "outputId": "9eff0799-8467-4610-ee63-d3b945657364"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "물론입니다! LangChain은 자연어 처리(NLP)와 관련된 애플리케이션을 쉽게 개발할 수 있도록 돕는 오픈소스 프레임워크입니다. 주로 대형 언어 모델(LLMs)을 활용하여 다양한 작업을 자동화하거나 확장하는 데 사용됩니다. \n",
      "\n",
      "LangChain의 주요 특징과 구성 요소는 다음과 같습니다:\n",
      "\n",
      "1. **체인(Chains):** 여러 개의 작업을 순차 또는 병렬로 연결하여 복잡한 프로세스를 구축할 수 있습니다. 예를 들어, 텍스트 요약 후 감정 분석을 하는 작업을 하나의 체인으로 만들 수 있습니다.\n",
      "\n",
      "2. **기능(Agents):** 사용자 입력에 따라 적절한 도구나 작업을 선택하고 실행하는 능동적인 시스템을 설계할 수 있습니다. 예를 들어, 질문에 따라 검색, 요약, 또는 번역 작업을 수행하는 에이전트를 만들 수 있습니다.\n",
      "\n",
      "3. **도구(Tools):** 외부 데이터베이스, 검색 API, 계산기 등 다양한 도구와 연동하여 언어 모델의 능력을 확장할 수 있습니다.\n",
      "\n",
      "4. **통합 및 확장성:** 다양한 언어 모델, API, 데이터 소스와 쉽게 연동할 수 있도록 설계되어 있어, 사용자 맞춤형 애플리케이션 개발이 용이합니다.\n",
      "\n",
      "이처럼 LangChain은 챗봇, 가상 비서, 자동화된 콘텐츠 생성, 정보 추출 등 다양한 NLP 애플리케이션 개발에 활용될 수 있으며, 개발자가 복잡한 로직을 쉽게 구성하고 관리할 수 있도록 도와줍니다.\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(\"한국어로 LangChain 에 대해서 설명해줘\").content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Messages\n",
    "- AIMessage: AI(인공지능) 모델이 생성한 메시지를 나타냅니다.  \n",
    "예를 들어, AI 모델이 사용자의 질문에 대해 응답을 생성할 때 이 클래스가 사용됩니다.\n",
    "\n",
    "- HumanMessage: 사람(사용자)이 생성한 메시지를 나타냅니다.  \n",
    "사용자가 입력한 텍스트나 질문 등이 여기에 해당됩니다.\n",
    "\n",
    "- StemMessage: AI 행동을 프라이밍하기 위한 메시지.\n",
    "시스템 메시지는 일반적으로 일련의 입력 메시지 중 첫 번째로 전달됩니다. 일반적으로 대화의 흐름을 제어하거나 특정 지침을 제공하기 위해 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "마치 다섯살 먹은 어린아이에게 설명하듯이 한국어로 쉽게 설명해 주세요.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "LangChain이 무엇인가요?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gYhhibXZSGTF",
    "outputId": "3d276aa8-39a2-4b85-b9aa-5bb43729783b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕! LangChain은 컴퓨터가 사람처럼 이야기를 하고, 정보를 찾거나 도와줄 수 있게 도와주는 도구라고 생각하면 돼. 예를 들어, 우리가 친구에게 질문하면 친구가 답해주는 것처럼, 컴퓨터도 우리가 묻는 것을 이해하고 답해줄 수 있게 만들어주는 거야. 그래서 여러 가지 일을 쉽게 할 수 있게 도와주는 도구라고 보면 돼!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 89, 'prompt_tokens': 43, 'total_tokens': 132, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_38343a2f8f', 'finish_reason': 'stop', 'logprobs': None}, id='run-d3632bb9-dbe1-4e7d-a2e9-8e908d8e995b-0', usage_metadata={'input_tokens': 43, 'output_tokens': 89, 'total_tokens': 132, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# system과 human/user 메시지를 이용한 기본 요청\n",
    "\n",
    "message = [\n",
    "    SystemMessage(content=system_prompt),\n",
    "    HumanMessage(content=user_prompt),\n",
    "]\n",
    "\n",
    "response = llm.invoke(message)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "AK7Xe8wnSQGa",
    "outputId": "c314481f-1ecb-4337-bf3c-08c274701b7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕! LangChain은 컴퓨터가 사람처럼 이야기를 하고, 정보를 찾거나 도와줄 수 있게 도와주는 도구라고 생각하면 돼. 예를 들어, 우리가 친구에게 질문하면 친구가 답해주는 것처럼, 컴퓨터도 우리가 묻는 것을 이해하고 답해줄 수 있게 만들어주는 거야. 그래서 여러 가지 일을 쉽게 할 수 있게 도와주는 도구라고 보면 돼!\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 수학 선생님"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81을 9로 나누면 9입니다.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"당신은  수학 문제를 잘 풀어주는 도움되는 assistant 입니다.\"),\n",
    "    HumanMessage(content=\"81을 9로 나누면 몇인가요?\")\n",
    "]\n",
    "\n",
    "result = llm.invoke(messages)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 곱하기 5는 50입니다.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"당신은  수학 문제를 잘 풀어주는 도움되는 assistant 입니다.\"),\n",
    "    HumanMessage(content=\"81을 9로 나누면 몇인가요?\"),\n",
    "    AIMessage(content=\"81을 9로 나누면 9입니다.\"),\n",
    "    HumanMessage(content=\"10 곱하기 5는 얼마인가요?\")\n",
    "]\n",
    "\n",
    "result = llm.invoke(messages)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2fi6_NvW3MaE"
   },
   "source": [
    "##  1. 프롬프트 템플릿과 로더를 사용하여 체인 구성  \n",
    "\n",
    "- LLM에서의 Chain 은 Data Processing 에서의 Pipeline 과 유사한 개념"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G447ezl5X5ye"
   },
   "source": [
    "### 체인의 구성 요소 - Runnables\n",
    "- 프롬프트 : LLM의 응답을 안내하는 템플릿  \n",
    "- LLM 또는 채팅 모델 : 프롬프트에 따라 응답을 생성하는 엔진  \n",
    "- 출력 파서 : LLM의 출력을 파싱하는 도구  \n",
    "- 도구 : LLM이 API에서 추가 정보를 추출하거나 코드를 실행하여 LLM을 에이전트로 전환할 수 있게 해주는 확장 기능  \n",
    "- 일반 함수 : 서로 연결될 수 있는 추가적인 일반 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Yt1j9kXR1h53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='\\n    당신은 AI 주제를 설명하는 데 도움이 되는 어시스턴트입니다. 다음 입력이 주어지면:\\n    {topic}\\n    주어진 주제에 대한 설명을 제공하세요.\\n')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# simple prompt template 생성\n",
    "# {topic} 변수에서 사용자의 query 가 대체된다.\n",
    "prompt_template = \"\"\"\n",
    "    당신은 AI 주제를 설명하는 데 도움이 되는 어시스턴트입니다. 다음 입력이 주어지면:\n",
    "    {topic}\n",
    "    주어진 주제에 대한 설명을 제공하세요.\n",
    "\"\"\"\n",
    "\n",
    "# prompt template 을 이용하여 prompt 생성 - old style\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=prompt_template,\n",
    ")\n",
    "\n",
    "# prompt template 을 이용하여 prompt 생성 - new style\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "id": "0vikrfE53yDk",
    "outputId": "adf40012-9025-4a1a-a591-da9fd5b4883c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain은 인공지능 및 자연어 처리 분야에서 사용되는 프레임워크로, 대규모 언어 모델(LLM)을 활용하여 복잡한 애플리케이션을 개발하는 데 도움을 주는 도구입니다. 이를 통해 개발자는 다양한 데이터 소스와 인터페이스를 연결하고, 자연어 이해 및 생성 기능을 손쉽게 통합할 수 있습니다. 예를 들어, 챗봇, 정보 검색 시스템, 자동 문서 작성 등 다양한 응용 프로그램을 빠르게 구축할 수 있도록 지원하는 것이 LangChain의 주요 목적입니다.\n"
     ]
    }
   ],
   "source": [
    "# pipe operator \"|\"\" 를 이용하여 하나 이상의 chain 을 결합\n",
    "chain = prompt | llm\n",
    "\n",
    "print(chain.invoke({\"topic\": \"LangChain이 뭐예요?\"}).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Runnable과 LangChain 표현 언어  \n",
    "\n",
    "- LCEL(LangChain Expression Language) 는 Runnables 를 chain 으로 구성하는 방법\n",
    "\n",
    "LCEL은 기본 구성 요소에서 복잡한 체인을 구축하는 것을 간소화합니다. 파이프 연산자(|)를 사용하여 다양한 구성 요소를 체인으로 연결하고 한 요소에서 다음 요소로 출력을 공급합니다. 이런 방식으로 구성된 체인의 간단한 예로는 모델과 출력 파서가 결합된 프롬프트가 있습니다.  이러한 구성 요소들을 runnables 라고 부릅니다.  \n",
    "\n",
    "`chain=prompt | model | output_parser`\n",
    "\n",
    "- Chain 구성  \n",
    "    - 체인에 대한 입력(일반적으로 사전)\n",
    "    - 입력은 프롬프트로 전송됩니다.\n",
    "    - 프롬프트 값은 LLM 또는 채팅 모델로 전송됩니다.\n",
    "    - Chatmodel이 채팅 메시지를 반환합니다.\n",
    "    - 파서는 채팅 메시지에서 문자열을 추출합니다.\n",
    "    - 문자열은 체인의 출력입니다\n",
    "\n",
    "- LangChain의 runnable 객체들:\n",
    "\n",
    "    - RunnableSequence : 여러 runnable 구성 요소를 연결하여 각 구성 요소가 입력을 처리하고 출력을 다음 구성 요소에 전달\n",
    "    - RunnableLambda : Python의 호출 가능한 요소(함수 등)를 실행 가능한 구성 요소로 바꿔서 체인으로 통합\n",
    "    - RunnablePassthrough : 입력을 변경하지 않고 통과시키거나 출력에 추가 키를 추가. placeholder 역할을 하거나 시퀀스에 유연하게 통합할 수 있다.\n",
    "    - RunnableParallel : 여러 개의 실행 파일을 동시에 실행하여 두 개의 체인이 동일한 입력에서 실행되지만 다른 출력을 반환하는 분기를 허용."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runnables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "3s0DaSYO_W0Y"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\n    당신은 AI 개념을 요약하는 유용한 조수입니다.\\n    {context}\\n    context를 한국어로 요약해 주세요.\\n')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "summarize_prompt_template = \"\"\"\n",
    "    당신은 AI 개념을 요약하는 유용한 조수입니다.\n",
    "    {context}\n",
    "    context를 한국어로 요약해 주세요.\n",
    "\"\"\"\n",
    "\n",
    "summarize_prompt = PromptTemplate.from_template(summarize_prompt_template)\n",
    "summarize_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "InN3aD1qGwmD"
   },
   "source": [
    "###  \"|\" 연산자를 이용하여 Runnable Sequence chain 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P0cahXhesl-E",
    "outputId": "eed661f4-9190-4da5-f8df-0139d0df7b64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = summarize_prompt | llm | output_parser\n",
    "\n",
    "print(type(chain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "id": "WpJAZmpOsjHA",
    "outputId": "147f9a53-6d84-4d3c-cae6-4322635e23f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain은 인공지능(AI)과 자연어 처리(NLP) 분야에서 사용되는 프레임워크로, 대형 언어 모델(LLM)을 활용하여 다양한 애플리케이션을 개발하는 데 도움을 주는 도구입니다. 이를 통해 개발자는 복잡한 자연어 이해 및 생성 작업을 쉽게 구현할 수 있으며, 데이터 소스와의 연동, 사용자 인터페이스 구축, 자동화된 워크플로우 설계 등을 지원합니다. 즉, LangChain은 AI 기반의 응용 프로그램 개발을 간소화하고 확장 가능하게 만들어주는 플랫폼입니다.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"context\": \"LangChain 에 대해 설명해 줘.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_VLKGZ1HO7d"
   },
   "source": [
    "### RunnableLambda 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oI9MZ0sasxQf",
    "outputId": "c5356d5c-6811-43af-9bfb-31fe88e2638e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "<class 'langchain_core.runnables.base.RunnableLambda'>\n",
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "# RunnableLambda를 사용하여 Python 함수를 체인에 삽입합니다.\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "summarize_chain = summarize_prompt | llm | output_parser\n",
    "print(type(summarize_chain))\n",
    "\n",
    "# 사용자 정의 람다 함수를 정의하고 이를 RunnableLambda에 래핑합니다.\n",
    "length_lambda = RunnableLambda(lambda summary: f\"요약된 길이: {len(summary)} 글자\")\n",
    "print(type(length_lambda))\n",
    "\n",
    "lambda_chain = summarize_chain | length_lambda\n",
    "print(type(lambda_chain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "TAa1W6iVHLnq",
    "outputId": "5b181616-a4f7-49a1-b807-9795fc389b9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'요약된 길이: 261 글자'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_chain.invoke({\"context\": \"LangChain 에 대해 설명해 줘\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DhIbYeOgIYyi",
    "outputId": "6ee972ca-751b-4b86-a8cd-fefe6fbe8c41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context'] input_types={} partial_variables={} template='\\n    당신은 AI 개념을 요약하는 유용한 조수입니다.\\n    {context}\\n    context를 한국어로 요약해 주세요.\\n'\n",
      "client=<openai.resources.chat.completions.Completions object at 0x0000023F42F8B880> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000023F42F94730> root_client=<openai.OpenAI object at 0x0000023F41191640> root_async_client=<openai.AsyncOpenAI object at 0x0000023F42F8B8B0> model_name='gpt-4.1-nano' model_kwargs={} openai_api_key=SecretStr('**********')\n",
      "\n",
      "RunnableLambda(lambda summary: f'요약된 길이: {len(summary)} 글자')\n"
     ]
    }
   ],
   "source": [
    "for step in lambda_chain.steps:\n",
    "    print(step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 체인이 달린 도구 사용  \n",
    "\n",
    "- 도구는 에이전트, 체인 또는 대형 언어 모델(LLM)이 세상과 상호 작용할 수 있게 하는 인터페이스입니다.\n",
    "    - Python REPL, Wikipdedia, YouTube, Zapier, Gradio, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "RkuqKhVpyKxm"
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade -q youtube_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ZF5O2LeB-vD",
    "outputId": "86cbdc7a-8466-410b-864b-7c67acc519db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.youtube.com/watch?v=1kPVTY0M4hE&pp=ygUP7L2U65Sp7ZWY64qUIEFJ0gcJCd4JAYcqIYzv', 'https://www.youtube.com/shorts/0FjOhEJwmB8']\n"
     ]
    }
   ],
   "source": [
    "# 유튜브를 검색하는 함수\n",
    "from langchain_community.tools import YouTubeSearchTool\n",
    "\n",
    "# YouTubeSearchTool 인스턴스 생성\n",
    "youtube_tool = YouTubeSearchTool()\n",
    "\n",
    "# 아무 키워드로 유튜브 검색 실행 --> 함수가 잘 실행되는 것 확인.\n",
    "results = youtube_tool.run(\"코딩하는 AI\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- YouTubeSearchTool 함수를 LLM 에 넘겨 주고 LLM이 이 함수를 이용하여 세상과 상호 작용 (유튜브 검색)할 수 있도록 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S5BZ28LTAtul",
    "outputId": "62f913a7-6b6c-415c-d494-4ad127a6a18d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_JGD46rSJD2muFAs32PgGUi4y', 'function': {'arguments': '{\"query\":\"코딩하는 AI\"}', 'name': 'youtube_search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 94, 'total_tokens': 111, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_38343a2f8f', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-c19b0b89-8eb8-4f2a-a0d2-746507269be7-0', tool_calls=[{'name': 'youtube_search', 'args': {'query': '코딩하는 AI'}, 'id': 'call_JGD46rSJD2muFAs32PgGUi4y', 'type': 'tool_call'}], usage_metadata={'input_tokens': 94, 'output_tokens': 17, 'total_tokens': 111, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1단계: LLM이 어떤 tool과 args를 쓸지 판단할 수 있도록 함\n",
    "# YouTube 도구를 LLM에 바인딩 --> OpenAI API 의 'tools=' parameter에 함수명과 \n",
    "# 함수 호출에 필요한 parameter 정보 전달\n",
    "llm_with_tools = llm.bind_tools([youtube_tool])\n",
    "\n",
    "msg = llm_with_tools.invoke(\"코딩하는 AI\")\n",
    "msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'youtube_search',\n",
       "  'args': {'query': '코딩하는 AI'},\n",
       "  'id': 'call_JGD46rSJD2muFAs32PgGUi4y',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# msg에서 OpenAI LLM이 구성해준 함수호출 parameter 발췌\n",
    "msg.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': '코딩하는 AI'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YouTubeSearchTool 호출에 필요한 parameter\n",
    "msg.tool_calls[0][\"args\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x0000023F42F8B880>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000023F42F94730>, root_client=<openai.OpenAI object at 0x0000023F41191640>, root_async_client=<openai.AsyncOpenAI object at 0x0000023F42F8B8B0>, model_name='gpt-4.1-nano', model_kwargs={}, openai_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'youtube_search', 'description': 'search for youtube videos associated with a person. the input to this tool should be a comma separated list, the first part contains a person name and the second a number that is the maximum number of video results to return aka num_results. the second part is optional', 'parameters': {'properties': {'query': {'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| RunnableLambda(lambda x: x.tool_calls[0]['args'])\n",
       "| YouTubeSearchTool()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2단계: Tool call → 파라미터 추출 → Tool 실행\n",
    "# llm_with_tools에서 추출된 인수로 YouTubeSearchTool을 사용하여 유튜브 검색 실행하는 chain 생성\n",
    "chain = llm_with_tools | (lambda x: x.tool_calls[0][\"args\"]) | youtube_tool\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['https://www.youtube.com/watch?v=7ttbyGI5igA&pp=ygUP7L2U65Sp7ZWY64qUIEFJ0gcJCd4JAYcqIYzv', 'https://www.youtube.com/watch?v=1kPVTY0M4hE&pp=ygUP7L2U65Sp7ZWY64qUIEFJ']\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke('코딩하는 AI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.youtube.com/watch?v=7ttbyGI5igA&pp=ygUP7L2U65Sp7ZWY64qUIEFJ0gcJCd4JAYcqIYzv',\n",
       " 'https://www.youtube.com/watch?v=1kPVTY0M4hE&pp=ygUP7L2U65Sp7ZWY64qUIEFJ']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "response = chain.invoke(\"코딩하는 AI\")\n",
    "ast.literal_eval(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chains 종류\n",
    "\n",
    "**LangChain**을 사용하여 다양한 체인(Chain) 및 LLM(대규모 언어 모델) 기반 애플리케이션을 구축합니다.\n",
    "\n",
    "**1. Simple Chain (단일 체인)**  \n",
    "- 하나의 프롬프트를 통해 LLM(OpenAI)을 사용하여 텍스트를 생성합니다.  \n",
    "\n",
    "\n",
    "**2. Simple Sequential Chain (연속 체인)**  \n",
    "-  여러 LLM 호출을 연속적으로 수행하여 출력을 다음 입력으로 전달합니다.  \n",
    "\n",
    "**3. Document 요약 체인**  \n",
    "- **목적:** 텍스트 문서를 요약합니다.  \n",
    "\n",
    "**4. 텍스트를 Vector Store로 변환**  \n",
    "- **4.1 VectortstoreIndexCreator**   \n",
    "- **4.2 Chroma DB 사용**  \n",
    "\n",
    "**5. HTTP Request Chain (웹 요청 체인)**  \n",
    "- HTTP 요청을 통해 외부 웹 데이터에서 정보를 추출합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Simple Chain (단일 체인)\n",
    "- 가장 기본적인 유형의 체인\n",
    "- 입력 프롬프트를 수신하고 이를 사용하여 텍스트를 생성하는 역할을 담당하는 언어 모델(LLM) 하나만 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국에서 꼭 가볼 만한 곳은 다양하지만, 몇 가지 추천드리자면 다음과 같습니다:\n",
      "\n",
      "1. 서울\n",
      "   - 경복궁: 조선 시대의 대표 궁궐로 역사와 아름다움을 동시에 느낄 수 있어요.\n",
      "   - 북촌 한옥마을: 전통 한옥과 골목길이 매력적인 곳입니다.\n",
      "   - 명동, 강남: 쇼핑과 먹거리, 문화 체험이 풍부한 지역입니다.\n",
      "2. 제주도\n",
      "   - 한라산: 등산과 자연 경관을 즐기기에 좋아요.\n",
      "   - 성산 일출봉: 일출 명소로 유명하며 멋진 풍경을 감상할 수 있습니다.\n",
      "   - 우도: 작은 섬으로 자연과 해양 스포츠를 즐기기 좋습니다.\n",
      "3. 부산\n",
      "   - 해운대 해수욕장: 아름다운 해변에서 여유로운 시간을 보내세요.\n",
      "   - 감천문화마을: 색색의 집과 예술적 분위기를 느낄 수 있습니다.\n",
      "   - 자갈치시장: 신선한 해산물과 활기찬 시장 분위기를 경험하세요.\n",
      "4. 경주\n",
      "   - 불국사와 석굴암: 유네스코 세계문화유산으로, 역사와 문화가 살아있는 곳입니다.\n",
      "   - 첨성대와 경주 양동마을: 고대 도시의 유적과 전통 가옥을 볼 수 있습니다.\n",
      "5. 강원도\n",
      "   - 설악산: 사계절 아름다운 자연 경관과 트레킹이 인기입니다.\n",
      "   - 강릉: 커피거리와 해변, 정동진에서 일출 감상도 추천합니다.\n",
      "\n",
      "이외에도 한국에는 아름다운 자연, 풍부한 역사 유적, 현대적인 도시 문화가 가득하니, 여행 목적과 관심사에 맞춰 선택하시면 좋겠습니다!\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate.from_template(\"{place}에서 가장 가 볼만한 곳은?\")\n",
    "\n",
    "chain = prompt | llm\n",
    "# chain = prompt.pipe(llm)\n",
    "\n",
    "# 입력 변수만 지정하여 체인을 실행\n",
    "print(chain.invoke(\"한국\").content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Simple Sequential Chains (연속 체인)\n",
    "- Sequential Chain은 언어 모델에 대한 일련의 연속 호출 포함\n",
    "- 이 접근 방식은 한 호출에서 생성된 출력을 다른 호출의 입력으로 활용할 때 특히 유용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['place'], input_types={}, partial_variables={}, template='{place}에서 방문하기 가장 좋은 장소 5곳을 추천해주세요\\n\\n응답:\\n')\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x0000023F42F8B880>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000023F42F94730>, root_client=<openai.OpenAI object at 0x0000023F41191640>, root_async_client=<openai.AsyncOpenAI object at 0x0000023F42F8B8B0>, model_name='gpt-4.1-nano', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| PromptTemplate(input_variables=['budget'], input_types={}, partial_variables={}, template='장소 목록이 주어지면, 모든 장소를 방문하는 데 드는 비용과 방문에 필요한 날짜를 현지 통화로 추산해 주십시오. \\n그리고 나서 예산 {budget}과 비교하여 충분한지, 부족한지 계산해 주세요.\\n\\n응답:\\n')\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x0000023F42F8B880>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000023F42F94730>, root_client=<openai.OpenAI object at 0x0000023F41191640>, root_async_client=<openai.AsyncOpenAI object at 0x0000023F42F8B8B0>, model_name='gpt-4.1-nano', model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template_1 = \"\"\"{place}에서 방문하기 가장 좋은 장소 5곳을 추천해주세요\n",
    "\n",
    "응답:\n",
    "\"\"\"\n",
    "\n",
    "prompt1 = PromptTemplate.from_template(template_1)\n",
    "\n",
    "chain1 = prompt1 | llm\n",
    "\n",
    "template_2 = \"\"\"장소 목록이 주어지면, 모든 장소를 방문하는 데 드는 비용과 방문에 필요한 날짜를 현지 통화로 추산해 주십시오. \n",
    "그리고 나서 예산 {budget}과 비교하여 충분한지, 부족한지 계산해 주세요.\n",
    "\n",
    "응답:\n",
    "\"\"\"\n",
    "\n",
    "prompt2 = PromptTemplate.from_template(template_2)\n",
    "\n",
    "chain2 = prompt2 | llm\n",
    "\n",
    "final_chain = chain1 | chain2\n",
    "final_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제공하신 장소 목록과 추천 내용을 분석할 때, 두 가지 주요 지표를 고려하겠습니다: (1) 비용과 방문 날짜 추산, (2) 추천 내용의 적합성 및 상세도.\n",
      "\n",
      "1. 비용과 방문 날짜 추산:\n",
      "- 현재 제공된 정보에는 장소별 방문 비용, 예상 체류 기간, 교통비, 식사비, 입장료 등의 구체적인 데이터가 없습니다.\n",
      "- 따라서, 장소 목록이 주어졌더라도 이를 바탕으로 한 비용과 일정 추산은 불가능합니다.\n",
      "- 일반적인 한국 여행 기준으로, 5곳을 모두 방문하는 데 드는 대략적인 비용은 다음과 같습니다:\n",
      "  * 교통비 (대중교통 또는 렌트카): 약 50,000원 ~ 100,000원\n",
      "  * 입장료 및 체험비: 약 20,000원 ~ 50,000원\n",
      "  * 식사 및 기타 경비: 약 30,000원 ~ 70,000원\n",
      "  * 숙박비 (3일 기준, 1인): 약 60,000원 ~ 150,000원\n",
      "  총합: 대략 160,000원 ~ 370,000원 (현지 통화 기준, 원화)\n",
      "\n",
      "- 방문 일정은 장소별 체류 시간과 이동 거리, 여유 시간에 따라 다르지만, 보통 3~4일 일정으로 계획하는 것이 적절합니다.\n",
      "\n",
      "2. 추천 내용의 적합성 및 상세도:\n",
      "- 현재 제공된 추천 장소는 한국의 대표적 관광지 5곳으로, 여행 목적에 부합하며 구체적인 설명도 포함되어 있습니다.\n",
      "- 추천 내용은 관광지별 특징, 체험 활동, 추천 이유 등을 잘 설명하고 있어 여행 계획에 참고하기 충분합니다.\n",
      "\n",
      "3. 결론:\n",
      "- 장소 목록이 주어졌지만, 비용과 날짜 추산을 위해 필요한 상세 데이터가 누락되어 있으므로, 비용과 일정에 대한 구체적 계산은 부족합니다.\n",
      "- 추천 내용은 충분히 상세하고 적절하다고 평가됩니다.\n",
      "\n",
      "요약:\n",
      "- 비용 및 일정 추산: **부족함** (구체적 데이터 필요)\n",
      "- 추천 내용의 적합성 및 상세도: **충분함**\n",
      "\n",
      "추가로, 비용과 일정 추산을 원하시면 방문하는 장소별 상세 정보(입장료, 교통편, 체류 시간 등)를 제공해 주세요.\n"
     ]
    }
   ],
   "source": [
    "review = final_chain.invoke({\"place\": \"한국\", \"budget\": \"1,000,000\"})\n",
    "print(review.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
